{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network approach to writer identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file you will be able to test your photo on the neural network classification by handwriting. \n",
    "\n",
    "Skip all functions to the end, there are an example hpw to call function.\n",
    "\n",
    "Make sure your photo is in PNG format and it contains minimal bordersof non-text image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "def fetch(img_dir, name):\n",
    "    #print('image ' + str(name))\n",
    "    img = cv2.imread(join(img_dir, name))\n",
    "    if img.shape == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    elif img.shape == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "\n",
    "def resize(img, size=(1024, 768)):\n",
    "    assert len(size) == 2\n",
    "    return cv2.resize(img, size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def pad(img, size=(1024, 768)):\n",
    "    assert len(img.shape) == 3\n",
    "    assert len(size) == 2\n",
    "    h, w, _ = img.shape\n",
    "    #assert w <= size[0] and h <= size[1]\n",
    "    pad_vert = np.ceil((size[1]-h) / 2).astype(np.uint32)\n",
    "    pad_hor = np.ceil((size[0]-w) / 2).astype(np.uint32)\n",
    "\n",
    "    padded = np.full((size[1], size[0], 3), 255).astype(np.uint8)\n",
    "    padded[pad_vert:pad_vert+h, pad_hor:pad_hor+w, :] = img.copy()\n",
    "    return padded\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import sys \n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "class WordsSequence(Sequence):\n",
    "    def __init__(self, img_dir, input_shape, x_set, y_set=None, batch_size=16):\n",
    "        if y_set is not None:\n",
    "            self.x, self.y = x_set, y_set\n",
    "            self.dataset = pd.DataFrame(data={'x': self.x, 'y': self.y, 'used': np.zeros_like(self.y)})\n",
    "            self.dataset['class_count'] = self.dataset.groupby('y')['y'].transform('count')\n",
    "        else:\n",
    "            self.x, self.y = x_set, None\n",
    "            \n",
    "        self.img_dir = img_dir\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            return np.array([self.preprocess(fetch(self.img_dir, name)) for name in batch_x])\n",
    "\n",
    "        unused = self.dataset.loc[self.dataset['used'] == 0]\n",
    "            \n",
    "        if len(unused) >= self.batch_size:\n",
    "            batch_indices = unused.sample(n=self.batch_size).index\n",
    "        else:\n",
    "            batch_indices = unused.sample(n=self.batch_size, replace=True).index\n",
    "\n",
    "        self.dataset.loc[batch_indices, 'used'] = 1\n",
    "        batch_x = self.dataset.iloc[batch_indices]['x'].values\n",
    "        batch_y = self.dataset.iloc[batch_indices]['y'].values\n",
    "        return np.array([self.preprocess(fetch(self.img_dir, name)) for name in batch_x]), np.array(batch_y)\n",
    "\n",
    "    def preprocess(self, img):\n",
    "        assert len(img.shape) == 3\n",
    "\n",
    "        h, w, _ = img.shape\n",
    "        if h / w <= self.input_shape[0] / self.input_shape[1]:\n",
    "            img = resize(img, (self.input_shape[1], int(self.input_shape[1] * h / w)))\n",
    "        else:\n",
    "            img = resize(img, (int(self.input_shape[0] * w / h), self.input_shape[0]))\n",
    "\n",
    "        img = pad(img, (self.input_shape[1], self.input_shape[0]))\n",
    "        return img / 255.  \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.y is not None:\n",
    "            self.dataset = pd.DataFrame(data={'x': self.x, 'y': self.y, 'used': np.zeros_like(self.y)})\n",
    "            self.dataset['class_count'] = self.dataset.groupby('y')['y'].transform('count')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def valid_triplets_mask(labels):\n",
    "    \"\"\"Compute the 3D boolean mask where mask[a, p, n] is True if (a, p, n) is a valid triplet,\n",
    "    as in a, p, n are distinct and labels[a] == labels[p], labels[a] != labels[n].\n",
    "\n",
    "    :param labels: tensor of shape (batch_size,)\n",
    "    :return mask: tf.bool tensor of shape (batch_size, batch_size, batch_size)\n",
    "    \"\"\"\n",
    "\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "    distinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    mask = tf.logical_and(distinct_indices, valid_labels)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def euclidean_distance(embeddings, squared=False):\n",
    "    \"\"\"Computes pairwise euclidean distance matrix with numerical stability.\n",
    "    output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
    "\n",
    "    :param embeddings: 2-D Tensor of size [number of data, feature dimension].\n",
    "    :param squared: Boolean, whether or not to square the pairwise distances.\n",
    "    :return dist: 2-D Tensor of size [number of data, number of data].\n",
    "    \"\"\"\n",
    "    dist_squared = tf.add(tf.reduce_sum(tf.square(embeddings), axis=1, keepdims=True),\n",
    "                          tf.reduce_sum(tf.square(tf.transpose(embeddings)), axis=0, keepdims=True)\n",
    "                          ) - 2.0 * tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "\n",
    "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    dist_squared = tf.maximum(dist_squared, 0.0)\n",
    "    # Get the mask where the zero distances are at.\n",
    "    error_mask = tf.less_equal(dist_squared, 0.0)\n",
    "    # Optionally take the sqrt.\n",
    "    dist = dist_squared if squared else tf.sqrt(dist_squared + tf.cast(error_mask, dtype=tf.float32) * 1e-16)\n",
    "    # Undo conditionally adding 1e-16.\n",
    "    dist = tf.multiply(dist, tf.cast(tf.logical_not(error_mask), dtype=tf.float32))\n",
    "\n",
    "    n_data = tf.shape(embeddings)[0]\n",
    "    # Explicitly set diagonals to zero.\n",
    "    mask_offdiagonals = tf.ones_like(dist) - tf.linalg.diag(tf.ones([n_data]))\n",
    "    dist = tf.multiply(dist, mask_offdiagonals)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def masked_maximum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise maximum over chosen elements.\n",
    "    :param data: 2-D float `Tensor` of size [n, m].\n",
    "    :param mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "    :param dim: The dimension over which to compute the maximum.\n",
    "    :return masked_maximums: N-D `Tensor`. The maximized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_minimums = tf.reduce_min(data, axis=dim, keepdims=True)\n",
    "    masked_maximums = tf.reduce_max(tf.multiply(data - axis_minimums, mask), axis=dim, keepdims=True) + axis_minimums\n",
    "    return masked_maximums\n",
    "\n",
    "\n",
    "def masked_minimum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise minimum over chosen elements.\n",
    "    :param data: 2-D float `Tensor` of size [n, m].\n",
    "    :param mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "    :param dim: The dimension over which to compute the minimum.\n",
    "    :return masked_minimums: N-D `Tensor`. The minimized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_maximums = tf.reduce_max(data, axis=dim, keepdims=True)\n",
    "    masked_minimums = tf.reduce_min(tf.multiply(data - axis_maximums, mask), axis=dim, keepdims=True) + axis_maximums\n",
    "    return masked_minimums\n",
    "\n",
    "\n",
    "def triplet_loss(margin=1.0, strategy='batch_semi_hard'):\n",
    "    \"\"\"Compute the triplet loss over the batch of embeddings. tf contrib inspired:\n",
    "    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/losses/python/metric_learning/metric_loss_ops.py\n",
    "\n",
    "    :param margin: margin that is going to be enforced by the triplet loss\n",
    "    :param strategy: string, that indicated whether we're using the 'batch hard', 'batch all' or 'batch_semi_hard' mining strategy\n",
    "    :return: a callback function that calculates the loss according to the specified strategy\n",
    "    \"\"\"\n",
    "    def get_loss_tensor(positive_dists, negative_dists):\n",
    "        \"\"\"Compute the triplet loss function tensor using specified margin:\n",
    "\n",
    "        :param positive_dists: positive distances tensor\n",
    "        :param negative_dists:  negative distances tensor\n",
    "        :return: resulting triplet loss tensor\n",
    "        \"\"\"\n",
    "        if margin == 'soft':\n",
    "            return tf.nn.softplus(positive_dists - negative_dists)\n",
    "\n",
    "        return tf.maximum(positive_dists - negative_dists + margin, 0.0)\n",
    "\n",
    "    def batch_semi_hard(labels, embeddings):\n",
    "        \"\"\"Computes the triplet loss with semi-hard negative mining.\n",
    "        The loss encourages the positive distances (between a pair of embeddings with\n",
    "        the same labels) to be smaller than the minimum negative distance among\n",
    "        which are at least greater than the positive distance plus the margin constant\n",
    "        (called semi-hard negative) in the mini-batch. If no such negative exists,\n",
    "        uses the largest negative distance instead.\n",
    "        See: https://arxiv.org/abs/1503.03832.\n",
    "\n",
    "        :param labels: 1-D tf.int32 `Tensor` with shape [batch_size] of multiclass integer labels.\n",
    "        :param embeddings: 2-D float `Tensor` of embedding vectors. Embeddings should be l2 normalized.\n",
    "        :return loss: tf.float32 scalar.\n",
    "        \"\"\"\n",
    "        labels = tf.reshape(labels, [-1, 1])\n",
    "        batch_size = tf.size(labels)\n",
    "        # Build pairwise squared distance matrix.\n",
    "        dist = euclidean_distance(embeddings, squared=True)\n",
    "        # Build pairwise binary adjacency matrix (equal label mask).\n",
    "        adjacency = tf.equal(labels, tf.transpose(labels))\n",
    "        # Invert so we can select negatives only.\n",
    "        adjacency_not = tf.logical_not(adjacency)\n",
    "\n",
    "        # Compute the mask.\n",
    "        dist_tile = tf.tile(dist, [batch_size, 1])  # stack dist matrix batch_size times, axis=0\n",
    "        mask = tf.logical_and(tf.tile(adjacency_not, [batch_size, 1]), tf.greater(dist_tile, tf.reshape(dist, [-1, 1])))\n",
    "        mask = tf.cast(mask, dtype=tf.float32)\n",
    "        is_negatives_outside = tf.reshape(tf.greater(tf.reduce_sum(mask, axis=1, keepdims=True), 0.0), [batch_size, batch_size])\n",
    "        is_negatives_outside = tf.transpose(is_negatives_outside)\n",
    "\n",
    "        # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "        negatives_outside = tf.reshape(masked_minimum(dist_tile, mask), [batch_size, batch_size])\n",
    "        negatives_outside = tf.transpose(negatives_outside)\n",
    "\n",
    "        # negatives_inside: largest D_an.\n",
    "        adjacency_not = tf.cast(adjacency_not, dtype=tf.float32)\n",
    "        negatives_inside = tf.tile(masked_maximum(dist, adjacency_not), [1, batch_size])\n",
    "\n",
    "        semi_hard_negatives = tf.where(is_negatives_outside, negatives_outside, negatives_inside)\n",
    "\n",
    "        # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "        #   in semihard, they take all positive pairs except the diagonal.\n",
    "        mask_positives = tf.cast(adjacency, dtype=tf.float32) - tf.linalg.diag(tf.ones([batch_size]))\n",
    "        n_positives = tf.reduce_sum(mask_positives)\n",
    "\n",
    "        loss_mat = get_loss_tensor(dist, semi_hard_negatives)\n",
    "        loss = tf.math.divide_no_nan(tf.reduce_sum(tf.multiply(loss_mat, mask_positives)), n_positives)\n",
    "        return loss\n",
    "\n",
    "    def batch_all(labels, embeddings):\n",
    "        \"\"\"Compute the loss by generating all the valid triplets and averaging over the positive ones\n",
    "\n",
    "        :param labels: 1-D tf.int32 `Tensor` with shape [batch_size] of multiclass integer labels.\n",
    "        :param embeddings: 2-D float `Tensor` of embedding vectors. Embeddings should be l2 normalized.\n",
    "        :return loss: tf.float32 scalar.\n",
    "        \"\"\"\n",
    "        dist = euclidean_distance(embeddings, squared=True)\n",
    "        #mask = tf.to_float(valid_triplets_mask(labels))\n",
    "        mask = tf.cast(valid_triplets_mask(labels), dtype=tf.float32)\n",
    "\n",
    "        anchor_positive_dist = tf.expand_dims(dist, 2)\n",
    "        anchor_negative_dist = tf.expand_dims(dist, 1)\n",
    "\n",
    "        loss_tensor = get_loss_tensor(anchor_positive_dist, anchor_negative_dist)\n",
    "        loss_tensor = tf.multiply(loss_tensor, mask)\n",
    "\n",
    "        #num_non_easy_triplets = tf.reduce_sum(tf.to_float(tf.greater(loss_tensor, 1e-16)))\n",
    "        num_non_easy_triplets = tf.reduce_sum(tf.cast(tf.greater(loss_tensor, 1e-16), dtype=tf.float32))\n",
    "        #loss = tf.div_no_nan(tf.reduce_sum(loss_tensor), num_non_easy_triplets)\n",
    "        loss = tf.math.divide_no_nan(tf.reduce_sum(loss_tensor), num_non_easy_triplets)\n",
    "        return loss\n",
    "\n",
    "    def batch_hard(labels, embeddings):\n",
    "        \"\"\"Compute the loss by generating only hardest valid triplets and averaging over the positive ones.\n",
    "        One triplet per embedding, i.e. per anchor\n",
    "\n",
    "        :param labels: 1-D tf.int32 `Tensor` with shape [batch_size] of multiclass integer labels.\n",
    "        :param embeddings: 2-D float `Tensor` of embedding vectors. Embeddings should be l2 normalized.\n",
    "        :return loss: tf.float32 scalar.\n",
    "        \"\"\"\n",
    "        dist = euclidean_distance(embeddings, squared=True)\n",
    "        adjacency = tf.cast(tf.equal(tf.reshape(labels, (-1, 1)), tf.reshape(labels, (1, -1))), tf.float32)\n",
    "\n",
    "        pos_dist = tf.reduce_max(adjacency * dist, axis=1)\n",
    "        inf = tf.constant(1e+9, tf.float32)\n",
    "        neg_dist = tf.reduce_min((adjacency * inf) + dist, axis=1)\n",
    "\n",
    "        loss_mat = get_loss_tensor(pos_dist, neg_dist)\n",
    "\n",
    "        num_non_easy_triplets = tf.reduce_sum(tf.to_float(tf.greater(loss_mat, 1e-16)))\n",
    "        loss = tf.div_no_nan(tf.reduce_sum(loss_mat), num_non_easy_triplets)\n",
    "        return loss\n",
    "\n",
    "    if strategy == 'batch_semi_hard':\n",
    "        return batch_semi_hard\n",
    "    elif strategy == 'batch hard':\n",
    "        return batch_hard\n",
    "    else:\n",
    "        return batch_all\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import  sample\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.python.keras.utils.generic_utils import Progbar\n",
    "\n",
    "\n",
    "def get_str2numb_numb2dict(vect):\n",
    "    str_to_ind_dict = {}\n",
    "    count = 0\n",
    "    for v in vect:\n",
    "        if v not in str_to_ind_dict.keys():\n",
    "            str_to_ind_dict[v] = count\n",
    "            count += 1\n",
    "    reverse_dict = {v:k for k, v in str_to_ind_dict.items()}\n",
    "    return str_to_ind_dict, reverse_dict\n",
    "\n",
    "def apply_dict(dict_keys, X):\n",
    "    res = []\n",
    "    for x in X:\n",
    "        res.append(dict_keys[x])\n",
    "    return res\n",
    "\n",
    "class ProgbarLossLogger(Callback):\n",
    "    def __init__(self):\n",
    "        super(ProgbarLossLogger, self).__init__()\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epochs = self.params['epochs']\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.seen = 0\n",
    "        self.target = self.params['steps']\n",
    "\n",
    "        if self.epochs > 1:\n",
    "            print('Epoch %d/%d' % (epoch + 1, self.epochs))\n",
    "        self.progbar = Progbar(target=self.target, verbose=True, stateful_metrics=['loss'])\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        if self.seen < self.target:\n",
    "            self.log_values = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        num_steps = logs.get('num_steps', 1)\n",
    "        self.seen += num_steps\n",
    "\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.log_values.append((k, logs[k]))\n",
    "        self.progbar.update(self.seen, self.log_values)\n",
    "        \n",
    "class TripletModel:\n",
    "    def __init__(self, alpha, input_shape, cache_dir):\n",
    "        self.alpha = alpha\n",
    "        self.input_shape = input_shape\n",
    "        self.cache_dir = cache_dir\n",
    "        if not os.path.isdir(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "        self.model = self.build_model()\n",
    "        self.embeddings = None\n",
    "        \n",
    "    def build_model(self):\n",
    "        \n",
    "        base_network = MobileNet(input_shape=self.input_shape, alpha=self.alpha, weights='imagenet', include_top=False, \n",
    "                                 pooling='avg')\n",
    "        x = Dense(128)(base_network.output)\n",
    "        x = Lambda(lambda x: K.l2_normalize(x, axis=1))(x)\n",
    "        model = Model(inputs=base_network.input, outputs=x)\n",
    "        model.summary()\n",
    "        return model\n",
    "           \n",
    "    def train(self, train_dir, train_csv, validation_dir, validation_csv, epochs, batch_size=32, learning_rate=0.001, margin=0.5):\n",
    "        train = pd.read_csv(train_csv)\n",
    "        # validation = pd.read_csv(validation_csv)\n",
    "        x_train, y_train = train['file_name'].as_matrix(), train['label'].as_matrix()\n",
    "        # x_validation, y_validation = validation['file_name'].as_matrix(), validation['label'].as_matrix()\n",
    "        \n",
    "        str2ind_train_dict, ind2str_train_dict = get_str2numb_numb2dict(y_train)\n",
    "        y_train = np.array(apply_dict(str2ind_train_dict, y_train))\n",
    "\n",
    "        # str2ind_val_dict, ind2str_val_dict = get_str2numb_numb2dict(y_validation)\n",
    "        # y_validation = np.array(apply_dict(str2ind_val_dict, y_validation))\n",
    "        \n",
    "        self.num_classes = len(np.unique(y_train))\n",
    "        train_generator = WordsSequence(train_dir, input_shape=self.input_shape, x_set=x_train, y_set=y_train, batch_size=batch_size)\n",
    "        # validation_generator = WordsSequence(validation_dir, input_shape=self.input_shape, x_set=validation_pairs, y_set=validation_y, batch_size=batch_size)\n",
    "\n",
    "        # optimize = RMSprop(lr=learning_rate)\n",
    "        optimize = Adam(lr=0.00001)\n",
    "        self.model.summary()\n",
    "        self.model.compile(loss=triplet_loss(margin=1.0, strategy=\"batch_semi_hard\"), optimizer=optimize)\n",
    "        #self.model.compile(loss=triplet_loss(margin=1.0, strategy=\"batch_all\"), optimizer=optimize)\n",
    "        \n",
    "        # validation_data=validation_generator, \n",
    "        self.model.fit_generator(train_generator, shuffle=True, epochs=epochs, verbose=1, \n",
    "        callbacks=[ModelCheckpoint(filepath=os.path.join(self.cache_dir, 'checkpoint-{epoch:02d}.h5'), save_weights_only=True)])\n",
    "        \n",
    "        self.model.save('final_model.h5')\n",
    "        self.save_weights('final_weights.h5')\n",
    "\n",
    "\n",
    "    def save_embeddings(self, filename):\n",
    "        self.embeddings.to_pickle(filename)\n",
    "    \n",
    "    def load_embeddings(self, filename):\n",
    "        self.embeddings = pd.read_pickle(filename)    \n",
    "        \n",
    "    def save_weights(self, filename):\n",
    "        self.model.save_weights(filename)\n",
    "        \n",
    "    def load_weights(self, filename):\n",
    "        self.model.load_weights(filename, by_name=True, skip_mismatch=True)\n",
    "        \n",
    "    \n",
    "    def make_embeddings(self, img_dir, csv, path_to_save, batch_size=32):\n",
    "        if self.embeddings is not None:\n",
    "            print(self.embeddings[0][0])\n",
    "            self.clf = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "            self.clf.fit(self.embeddings[0][0], self.embeddings[0][1])\n",
    "        else:\n",
    "            data = pd.read_csv(csv)\n",
    "            x, y = data['file_name'].as_matrix(), data['label'].as_matrix()\n",
    "            \n",
    "            self.str2ind_test_dict, self.ind2str_test_dict = get_str2numb_numb2dict(y)\n",
    "            y = np.array(apply_dict(self.str2ind_test_dict, y))\n",
    "\n",
    "            words = WordsSequence(img_dir, input_shape=self.input_shape, x_set=x, batch_size=batch_size)\n",
    "            pred = self.model.predict_generator(words, verbose=1)\n",
    "\n",
    "            self.clf = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "            self.clf.fit(pred, y) \n",
    "     \n",
    "            self.embeddings =  pd.DataFrame(data=[pred, y])\n",
    "            self.save_embeddings(path_to_save)\n",
    "    \n",
    "    def predict(self, img_dir, test_csv, author_tested = '', batch_size=32):\n",
    "        self.model.summary()\n",
    "        test = pd.read_csv(test_csv)\n",
    "        x_test, y_test = test['file_name'].as_matrix(), test['label'].as_matrix()\n",
    "        \n",
    "        str2ind_test_dict, ind2str_test_dict = get_str2numb_numb2dict(y_test)\n",
    "        test_y = np.array(apply_dict(str2ind_test_dict, y_test))\n",
    "\n",
    "        words = WordsSequence(img_dir, input_shape=self.input_shape, x_set=x_test, batch_size=batch_size)\n",
    "        test_embeddings = self.model.predict_generator(words, verbose=1)\n",
    " \n",
    "        res = self.clf.predict(test_embeddings) \n",
    "        predict = np.array(apply_dict(ind2str_test_dict , res))\n",
    "        \n",
    "        autors = np.unique(y_test)\n",
    "        autor_ind = [np.argwhere(y_test == a) for a in autors]\n",
    "            \n",
    "        if author_tested == '':\n",
    "            \n",
    "            count = 0\n",
    "            for i,j in zip(predict, y_test):\n",
    "                if i == j:\n",
    "                    count += 1\n",
    "            print('word accuracy: ', count / len(y_test))\n",
    "        \n",
    "            count = 0            \n",
    "            for i,inds in enumerate(autor_ind):\n",
    "                p = Counter(np.ravel(predict[inds])).most_common(1)[0][0]\n",
    "                if p == autors[i]:\n",
    "                    print('совпал автор №  ' + str(autors[i]))\n",
    "                    count += 1\n",
    "                else:\n",
    "                     print('автор №   ' + str(autors[i]) + ' не совпал с ' + str(p))\n",
    "\n",
    "            print('top-1 autor accuracy: ', count / len(autors))\n",
    "\n",
    "\n",
    "            count = 0\n",
    "            for i,inds in enumerate(autor_ind):\n",
    "                p = [pair[0] for pair in Counter(np.ravel(predict[inds])).most_common(5)]\n",
    "                if autors[i] in p:\n",
    "                    count += 1\n",
    "\n",
    "            print('top-5 autor accuracy: ', count / len(autors))\n",
    "        \n",
    "        else:\n",
    "            autors = np.unique(y_test)\n",
    "            autor_ind = [np.argwhere(y_test == a) for a in autors]\n",
    "            for i,inds in enumerate(autor_ind):\n",
    "                if autors[i] == img_name:\n",
    "                    p = Counter(np.ravel(predict[inds])).most_common(100)[0][0]\n",
    "            print('Words identified with these authors: ')\n",
    "            #print(np.unique(p))\n",
    "            return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to word selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import plot\n",
    "import statistics   \n",
    "from statistics import mean\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "\n",
    "GREEN = (0, 255, 0)\n",
    "BLUR = (255, 0, 0)\n",
    "RED = (0, 0, 255)\n",
    "\n",
    "def show(img):\n",
    "    \"\"\"show rgb image\"\"\"\n",
    "    ax = plt.axes([0,0,4,4], frameon=False)\n",
    "    ax.set_axis_off()\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "def show_gray(img):\n",
    "    \"\"\"show grayscale image\"\"\"\n",
    "    ax = plt.axes([0,0,4,4], frameon=False)\n",
    "    ax.set_axis_off()\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "    \n",
    "def save_words(path, words):\n",
    "    for i, word in enumerate(words):\n",
    "        cv2.imwrite(os.path.join(path , 'word_' + str(i) + '.png'), word)\n",
    "        \n",
    "def sort_w(word):\n",
    "    shape = word.shape\n",
    "    return shape[1]\n",
    "\n",
    "class RECT:\n",
    "    \"\"\"Class that helps to  find where one contours are inside others\"\"\"\n",
    "    def __init__(self, x, y, h,  w):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "def is_rectangle_internal(R1,  R2):\n",
    "    \"\"\"If one rectangle contains another\"\"\"\n",
    "    if ((R2.x+R2.w) < (R1.x+R1.w)) and ((R2.x) > (R1.x)) and ((R2.y) > (R1.y)) and ((R2.y+R2.h) < (R1.y+R1.h)):\n",
    "            return True;\n",
    "    else:\n",
    "        return False;\n",
    "\n",
    "def get_rectangles_from_contours(contours, h_img, w_img):\n",
    "    \"\"\"Get all rectangles from contours, delete internal contours\"\"\"\n",
    "    rectangles = []\n",
    "    for i, ctr in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        if w >= w_img/50 and h >= h_img/50 and w <= w_img/2 and h <= h_img/10:\n",
    "            r = RECT(x,y,h, w)\n",
    "            rectangles += [r]\n",
    "    #Get only internal rectangles\n",
    "    resulted_rectangles = []\n",
    "    for i in range (len(rectangles)):\n",
    "        isSmall = True\n",
    "        r1 = rectangles[i]\n",
    "        for j in range(i+1, len(rectangles)):\n",
    "            r2 = rectangles[j]\n",
    "            if (is_rectangle_internal(r1, r2)):\n",
    "                isSmall = False       \n",
    "        if isSmall:\n",
    "            resulted_rectangles += [r1]\n",
    "    return resulted_rectangles\n",
    "\n",
    "def percent_of_white_pixels_word(thresh_image):\n",
    "    \"\"\"Count percent of white pixels in the concrete word\"\"\"\n",
    "    white_pixels = 0\n",
    "    h, w, = thresh_image.shape\n",
    "    for i in range (h):\n",
    "        for j in range (w):\n",
    "            if (thresh_image[i][j] == 255):\n",
    "                white_pixels += 1\n",
    "\n",
    "    all_pixels = h *  w\n",
    "    return (round(white_pixels/all_pixels, 2))\n",
    "\n",
    "def percent_of_white_pixels(img, thresh_index):\n",
    "    \"\"\"Count percent of white pixels in the whole image\"\"\"\n",
    "    print(\"thresh_index\" + str(thresh_index))\n",
    "    h, w, _ = img.shape\n",
    "    # delete boundaries\n",
    "    image = img[40:h-40, 40:w-40]\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,thresh_index,255,cv2.THRESH_BINARY_INV)\n",
    "    show(thresh)\n",
    "    white_pixels = 0\n",
    "    h, w = thresh.shape\n",
    "    for i in range (h):\n",
    "        for j in range (w):\n",
    "            if (thresh[i][j] == 255):\n",
    "                white_pixels += 1\n",
    "\n",
    "    all_pixels = h *  w\n",
    "    return (round(white_pixels/all_pixels, 2))\n",
    "\n",
    "        \n",
    "def compare_thresh_indexes(img):\n",
    "    \"\"\"Determines which binarization index is the best is the best \"\"\"\n",
    "    #values to check which index is optimal for binarization\n",
    "    thresh_indexes = [107, 127, 147, 167, 187, 207, 227 ]\n",
    "    dict_with_norm_white_percent = {}\n",
    "    dict_with_big_white_percent = {}\n",
    "    best_percent = 100; best_index = 0; best_val = 100\n",
    "    \n",
    "    # Add to dictionary all values of each index binarization\n",
    "    for index in thresh_indexes:\n",
    "        percent = percent_of_white_pixels(img, index)\n",
    "        if percent >= 0.01 and percent <= 0.15:\n",
    "            dict_with_norm_white_percent[index] = percent\n",
    "            print(\"index \" + str(index) + \" - \" + str(percent))\n",
    "        else:\n",
    "            dict_with_big_white_percent[index] = percent\n",
    "            \n",
    "    # Select best index of binarization\n",
    "    if len(dict_with_norm_white_percent) == 0:\n",
    "        for index in dict_with_big_white_percent.keys():\n",
    "            if dict_with_big_white_percent[index] <= best_percent:\n",
    "                best_percent = dict_with_big_white_percent[index]\n",
    "                best_index = index\n",
    "            \n",
    "    else:\n",
    "        for index in dict_with_norm_white_percent.keys():\n",
    "            new_value = math.fabs(dict_with_norm_white_percent[index] - 0.07)\n",
    "            if new_value <= best_val:\n",
    "                best_val = new_value\n",
    "                best_percent = dict_with_norm_white_percent[index]\n",
    "                best_index = index\n",
    "    print(\"best index = \" + str(index) + \" - best_percent = \" + str(best_percent))\n",
    "    return index\n",
    "\n",
    "def get_thresh_image(img, index):\n",
    "    if len(img.shape) == 3:\n",
    "        h, w, _  = img.shape\n",
    "    else:\n",
    "        h, w  = img.shape\n",
    "    contour = [0, 0, w, h]\n",
    "    binary = cv2.cvtColor(img.copy(), cv2.COLOR_RGB2GRAY)\n",
    "    show_gray(binary)\n",
    "    ret,thresh = cv2.threshold(binary,index,255,cv2.THRESH_BINARY)\n",
    "    show(thresh)\n",
    "    return thresh\n",
    "\n",
    "def prepare_binary_contour(contour):\n",
    "    \"\"\"Aggregate function to select lines\"\"\"\n",
    "    hists, average_black_height, average_white_height, lines_count = build_hists(contour)\n",
    "\n",
    "    sm_hists = smooth_hists(hists)\n",
    "    #show_hists(sm_hists)\n",
    "    valleys = find_valleys(sm_hists)\n",
    "    #show_valleys(contour, valleys)\n",
    "    lines, avg_height = get_lines(contour, valleys) \n",
    "\n",
    "    #show_lines(contour, lines)\n",
    "    if lines != []:\n",
    "        lines = filter_chunks(lines, average_black_height, average_white_height)\n",
    "    else: \n",
    "        return []\n",
    "\n",
    "    #show_lines(contour, lines)\n",
    "    created_lines = get_first_approach_lines(lines, average_black_height)\n",
    "    #draw_lines(contour, created_lines)\n",
    "\n",
    "    created_lines = sorted(created_lines, key = lambda x: x.data[0].y)\n",
    "    #draw_lines(contour, created_lines)\n",
    "    extracted_lines = cut_lines(contour, created_lines)\n",
    "    return extracted_lines\n",
    "\n",
    "\n",
    "def build_hists(image):\n",
    "    \"\"\"Build hist to each chunk\"\"\"\n",
    "    hists = []\n",
    "    chunks = get_chunks(image)\n",
    "    black_height = []; white_height = []\n",
    "    lines_count = []\n",
    "    for i, val in enumerate(chunks[:-1]):\n",
    "        chunk = image[:, val : chunks[i + 1]]\n",
    "        hist = np.sum(1 - (chunk / 255), axis=1)\n",
    "        current_black_height = 0\n",
    "        current_white_height = 0\n",
    "        count = 0\n",
    "        if hist[0] == 0:\n",
    "            current_black_height += 1\n",
    "        else:\n",
    "            current_white_height += 1\n",
    "        for pix in hist[1:]:\n",
    "            if pix == 0:\n",
    "                if current_black_height > 0:\n",
    "                    current_black_height += 1\n",
    "                else:\n",
    "                    current_black_height += 1\n",
    "                    white_height.append(current_white_height)\n",
    "                    current_white_height = 0\n",
    "            else:\n",
    "                if current_white_height > 0:\n",
    "                    current_white_height += 1\n",
    "                else:\n",
    "                    current_white_height += 1\n",
    "                    black_height.append(current_black_height)\n",
    "                    count += 1\n",
    "                    current_black_height = 0\n",
    "        lines_count.append(count)\n",
    "        hists.append(hist)\n",
    "    return hists, mean(black_height), mean(white_height), lines_count\n",
    "\n",
    "def smooth_hists(hists):\n",
    "    \"\"\"Smooth hists witch is got in function build_hists\"\"\"\n",
    "    new_hists = []\n",
    "    for hist in hists:\n",
    "        new_hists.append(median_smooth(hist))\n",
    "    return new_hists\n",
    "\n",
    "def median_smooth(signal, kernel_size = 5):\n",
    "    \"\"\"Smooth signal\"\"\"\n",
    "    smooth_signal = []\n",
    "    for i, val in enumerate(signal[:-kernel_size]):\n",
    "        smooth_signal.append(sum(signal[i: i + kernel_size]) / kernel_size)\n",
    "    return np.array(smooth_signal)\n",
    "\n",
    "def show_hists(hists):\n",
    "    \"\"\"\n",
    "    Draw hists\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    y = np.arange(len(hists[0]))\n",
    "    for i in range(len(hists)):\n",
    "        h = hists[i]\n",
    "        plt.plot(h[::-1] + i*35, y)\n",
    "    ax = plt.axes([0,0,1,1], frameon=False)\n",
    "    ax.set_axis_off()\n",
    "    plt.show()\n",
    "    fig.savefig('temp.png', dpi=fig.dpi)\n",
    "    \n",
    "def find_valleys(sm_hists, thresh = 1):\n",
    "    \"\"\"Finding troughs on smoothed histograms\"\"\"\n",
    "    valleys = []\n",
    "    interval_average_height = []\n",
    "    for curr in sm_hists:\n",
    "        curr[curr < thresh] = 0\n",
    "        valleys_ind, curr_valley = [], []\n",
    "        prev = 1\n",
    "        for i, val in enumerate(curr[:-1]):\n",
    "            if (val == 0 and prev != 0):\n",
    "                curr_valley.append(i)\n",
    "            if (val == 0 and curr[i + 1] != 0):\n",
    "                curr_valley.append(i)\n",
    "            if len(curr_valley) == 2:\n",
    "                valleys_ind.append(curr_valley)\n",
    "                interval_average_height.append(curr_valley[1] - curr_valley[0])\n",
    "                curr_valley = []\n",
    "            if len(curr_valley) == 1 and (i == len(curr) - 2):\n",
    "                curr_valley.append(i)\n",
    "                valleys_ind.append(curr_valley)\n",
    "            prev = val\n",
    "        valleys.append(valleys_ind)\n",
    "    return valleys\n",
    "\n",
    "def show_valleys(image, valleys, channels = 2):\n",
    "    chunks = get_chunks(image, channels)\n",
    "    img = image.copy()\n",
    "    \n",
    "    for i, y in enumerate(chunks[:-1]):\n",
    "        for (x_1, x_2) in valleys[i]:\n",
    "            cv2.line(img, (y, x_1), (chunks[i + 1], x_1),GREEN,3)\n",
    "            cv2.line(img, (y, x_2), (chunks[i + 1], x_2),RED,3)\n",
    "    if channels == 3:\n",
    "        show(img)\n",
    "    else:\n",
    "        show_gray(img)     \n",
    "        \n",
    "def get_lines(image, valleys, channels = 2):\n",
    "    \"\"\"Calculate the middle line in the trough and the average line height\"\"\"\n",
    "    total_lines = []\n",
    "    chunks = get_chunks(image, channels)\n",
    "    for i, chunk in enumerate(chunks[:-1]):\n",
    "        chunk_lines = []\n",
    "        for val in valleys[i]:\n",
    "            chunk_lines.append(Trait(chunk, chunks[i+1], sum(val) // len(val)))\n",
    "        total_lines.append(chunk_lines)\n",
    "    \n",
    "    height = []\n",
    "    for i, line in enumerate(total_lines):\n",
    "        for j, trait in enumerate(line[:-1]):\n",
    "            height.append(abs(trait.y_1 - line[j + 1].y_1))\n",
    "    height = sum(height) / len(height)\n",
    "    return total_lines, height\n",
    "\n",
    "def show_lines(image, lines):\n",
    "    img = image.copy()\n",
    "    for chunk in lines:\n",
    "        for line in chunk:\n",
    "            cv2.line(img, (line.x_1, line.y_1), (line.x_2, line.y_1),GREEN,3)\n",
    "    show(img)\n",
    "    \n",
    "def get_chunks(image, channels = 1):\n",
    "    \"\"\"\n",
    "    Split image on chunks, each chunk is 10 percent of image width\n",
    "    return: array with y-coordinates\n",
    "    \"\"\"\n",
    "    n, m = image.shape\n",
    "    return np.arange(0, m + 1, m // 10)\n",
    "\n",
    "Point = namedtuple('Point', ['x' , 'y'])\n",
    "\n",
    "class Line:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.last_trait = None\n",
    "        \n",
    "    def continue_line(self, trait):\n",
    "        self.data.append(Point(trait.x_1, trait.y_1))\n",
    "        self.data.append(Point(trait.x_2, trait.y_1))\n",
    "\n",
    "class Trait:\n",
    "    def __init__(self, x_1, x_2, y_1):\n",
    "        self.x_1 = x_1\n",
    "        self.x_2 = x_2\n",
    "        self.y_1 = y_1\n",
    "        #self.y_2 = y_2\n",
    "    \n",
    "    def dist(self, other):\n",
    "        return ((self.x_2 - other.x_1) ** 2 + (self.y_1 - other.y_1) ** 2) ** (1 / 2)\n",
    "    \n",
    "    def print_(self):\n",
    "        print('x_1: {}  x_2: {}  y: {}'.format(self.x_1, self.x_2, self.y_1))\n",
    "\n",
    "        \n",
    "def filter_chunk(chunk, avg_black_height, average_white_height):\n",
    "    if chunk == []:\n",
    "        return []\n",
    "    prev = chunk[0]\n",
    "    new_traits = [prev]\n",
    "    for i, trait in enumerate(chunk[1:-1]):\n",
    "        next_trait = chunk[i + 2]\n",
    "        if abs(prev.y_1 - trait.y_1) > (avg_black_height + average_white_height/4) \\\n",
    "            and abs(next_trait.y_1 - trait.y_1) > (avg_black_height+ average_white_height/4):\n",
    "            new_traits.append(trait)\n",
    "            prev = trait\n",
    "    new_traits.append(chunk[-1])\n",
    "    return new_traits\n",
    "\n",
    "def filter_chunks(chunks, avg_black_height, average_white_height):\n",
    "    new_chunks = []\n",
    "    if chunks == []:\n",
    "        return []\n",
    "    for chunk in chunks:\n",
    "        new_chunks.append(filter_chunk(chunk, avg_black_height, average_white_height))\n",
    "    return new_chunks\n",
    "\n",
    "def get_first_approach_lines(chunk_with_traits, avg_height):\n",
    "    \"\"\"\n",
    "    Get first approach of splitting lines\n",
    "    \"\"\"\n",
    "    if chunk_with_traits is None:\n",
    "        return []\n",
    "    created_lines = connect_two_chunks(chunk_with_traits[0], chunk_with_traits[1], avg_height)\n",
    "    connect_start_lines_with_next_chunks(created_lines, chunk_with_traits[2], avg_height)\n",
    "    for chunk in chunk_with_traits[3:]:\n",
    "        connect_lines_with_chunk(created_lines, chunk, avg_height)\n",
    "    #print('avg height = ' + str(avg_height))\n",
    "    return created_lines\n",
    "                \n",
    "def connect_two_chunks(chunk_1, chunk_2, avg_height):\n",
    "    if chunk_1 == [] or chunk_2 == []:\n",
    "        return []\n",
    "    all_inds_from_chunk2 = [i for i in range(len(chunk_2))]\n",
    "    used_traits_from_chunk2 = []\n",
    "    created_lines = []\n",
    "    for trait_1 in chunk_1:\n",
    "        minimum = sys.maxsize\n",
    "        min_trait = Trait(trait_1.x_1, trait_1.x_2, 100)\n",
    "        for j, trait_2 in enumerate(chunk_2):\n",
    "            if trait_1.dist(trait_2) <  minimum:\n",
    "                minimum = trait_1.dist(trait_2)\n",
    "                min_trait = trait_2\n",
    "            if minimum >= 2 * avg_height / 3:\n",
    "                min_trait = Trait(min_trait.x_1, min_trait.x_2, trait_1.y_1)\n",
    "                \n",
    "            if (min_trait.x_1 == trait_2.x_1) and (min_trait.x_2 == trait_2.x_2) \\\n",
    "                and (min_trait.y_1 == trait_2.y_1):\n",
    "                used_traits_from_chunk2.append(j)\n",
    "        new_line = Line()\n",
    "        new_line.continue_line(trait_1)\n",
    "        new_line.continue_line(min_trait)\n",
    "        new_line.last_trait = min_trait\n",
    "        created_lines.append(new_line)\n",
    "    unused_traits = list(set(all_inds_from_chunk2) - set(used_traits_from_chunk2))\n",
    "\n",
    "    for trait in unused_traits:\n",
    "        chunk = chunk_2[trait]\n",
    "        new_line = Line()\n",
    "        start_trait = Trait(chunk_1[0].x_1, chunk.x_1, chunk.y_1)\n",
    "        new_line.continue_line(start_trait)\n",
    "        new_line.continue_line(chunk)\n",
    "        new_line.last_trait = chunk\n",
    "        created_lines.append(new_line)\n",
    "    return created_lines\n",
    "\n",
    "def connect_start_lines_with_next_chunks(lines, chunk, avg_height):\n",
    "    all_inds_from_chunk = [i for i in range(len(chunk))]\n",
    "    used_traits_from_chunk = []\n",
    "    for line in lines:\n",
    "        trait_1 = line.last_trait\n",
    "        min_trait = Trait(trait_1.x_1, trait_1.x_2, 100)\n",
    "        minimum = sys.maxsize\n",
    "        for j, trait_2 in enumerate(chunk):\n",
    "            if trait_1.dist(trait_2) <  minimum:\n",
    "                minimum = trait_1.dist(trait_2)\n",
    "                min_trait = trait_2\n",
    "            if minimum >= avg_height / 2.0:\n",
    "                min_trait = Trait(min_trait.x_1, min_trait.x_2, trait_1.y_1)\n",
    "            if (min_trait.x_1 == trait_2.x_1) and (min_trait.x_2 == trait_2.x_2) \\\n",
    "                and (min_trait.y_1 == trait_2.y_1):\n",
    "                used_traits_from_chunk.append(j)\n",
    "        line.continue_line(min_trait)\n",
    "        line.last_trait = min_trait\n",
    "    unused_traits = list(set(all_inds_from_chunk) - set(used_traits_from_chunk))\n",
    "    print(unused_traits)\n",
    "    for i in unused_traits:\n",
    "        trait = chunk[i]\n",
    "        start_trait = Trait(0, trait.x_1, trait.y_1)\n",
    "        new_line = Line()\n",
    "        new_line.continue_line(start_trait)\n",
    "        new_line.continue_line(trait)\n",
    "        new_line.last_trait = trait\n",
    "        lines.append(new_line)\n",
    "        \n",
    "def connect_lines_with_chunk(lines, chunk, avg_height):\n",
    "    \"\"\" Combine the remaining chunk and already created lines\"\"\"\n",
    "    for line in lines: \n",
    "        trait_1 = line.last_trait\n",
    "        minimum = sys.maxsize\n",
    "        if len(chunk) == 0:\n",
    "            return\n",
    "        for trait_2 in chunk:\n",
    "            if trait_1.dist(trait_2) <  minimum:\n",
    "                minimum = trait_1.dist(trait_2)\n",
    "                min_trait = trait_2\n",
    "            if minimum >=  avg_height / 1:\n",
    "            \n",
    "                min_trait = Trait(min_trait.x_1, min_trait.x_2, trait_1.y_1)\n",
    "        line.continue_line(min_trait)\n",
    "        line.last_trait = min_trait\n",
    "        \n",
    "def cut_line(image, line_1, line_2):\n",
    "    n, m = image.shape\n",
    "    img = image.copy()\n",
    "    x_list = []\n",
    "    for i, point in enumerate(line_1.data[:-1]):\n",
    "        next_point = line_1.data[i + 1]\n",
    "        img[:point.y, point.x:next_point.x] = 255\n",
    "        x_list.append(point.x)\n",
    "    for i, point in enumerate(line_2.data[:-1]):\n",
    "        next_point = line_2.data[i + 1]\n",
    "        img[point.y:n, point.x:next_point.x] = 255\n",
    "        x_list.append(point.x)\n",
    "    max_x = max(x_list)\n",
    "    img[:, max_x:m] = 255\n",
    "    inds = np.argwhere(img == 0)\n",
    "    if len(inds) != 0:\n",
    "        x_min = min(inds[:, 0])\n",
    "        x_max = max(inds[:, 0])\n",
    "        y_min = min(inds[:, 1])\n",
    "        y_max = max(inds[:, 1])\n",
    "        show_gray(img[x_min:x_max,:])\n",
    "        return img[x_min:x_max, y_min:y_max]       \n",
    "\n",
    "def cut_lines(image, created_lines):\n",
    "    lines = []\n",
    "    for i, line in enumerate(created_lines[:-1]):\n",
    "        lines.append(cut_line(image, line, created_lines[i + 1]))\n",
    "    return lines\n",
    "\n",
    "def draw_line(image, line):\n",
    "    img = image.copy()\n",
    "    color = [random.randint(0, 255) for _ in range(3)]\n",
    "    for i, point in enumerate(line.data[:-1]):\n",
    "        next_point = line.data[i + 1]\n",
    "        cv2.line(img, (point.x, point.y), (next_point.x, next_point.y), color ,3)\n",
    "    return img\n",
    "    \n",
    "def draw_lines(image, lines, channels = 2):\n",
    "    \"\"\"Draw splitting lines\"\"\"\n",
    "    img = image.copy()\n",
    "    for line in lines:\n",
    "        img = draw_line(img, line)\n",
    "    if channels == 3:\n",
    "        cv2.imwrite(\"12345.png\", img)\n",
    "        show(img)\n",
    "    else:\n",
    "        show_gray(img)\n",
    "        \n",
    "def get_words_from_line(line, min_width = 10, thresh =  100): #400000\n",
    "    \"\"\"\n",
    "    line : grayscale line\n",
    "    min_width : min space length\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    if line is None:\n",
    "        return words\n",
    "    n, m = line.shape\n",
    "    image = cv2.bitwise_not(line)\n",
    "    y = np.sum(image // 255, axis = 0)\n",
    "\n",
    "    _, inds = np.where([y == 0])\n",
    "\n",
    "    start = 0\n",
    "    spaces = []\n",
    "    for i, ind in enumerate(inds[:-1]):\n",
    "        if (ind + 1 == inds[i + 1]) and (start == 0):\n",
    "            start = ind\n",
    "        elif (ind + 1 < inds[i + 1]) and (start != 0):\n",
    "            if (ind - start) >= min_width:\n",
    "                spaces.append([int(start), int(ind)])\n",
    "                start = 0\n",
    "            else:\n",
    "                start = 0\n",
    "\n",
    "    spaces = np.ravel(spaces)\n",
    "    spaces = np.insert(spaces, [0, len(spaces)], [0, m])\n",
    "    spaces = spaces.reshape(len(spaces) // 2, 2)     \n",
    "    \n",
    "    for inds in spaces:\n",
    "        word = line[:, int(inds[0]): int(inds[1])]\n",
    "        print(\"sum\", np.sum(word))\n",
    "        #show_gray(word)\n",
    "        if np.sum(1 - (word / 255)) > thresh:\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "def extract_words(lines):\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        words += get_words_from_line(line)\n",
    "    return words\n",
    "\n",
    "def contours_extraction(img_path, thresh_index):\n",
    "    img = cv2.imread(img_path)\n",
    "    h_img, w_img, _ = img.shape\n",
    "    image = img[40:h_img-40, 40:w_img-40]\n",
    "    #show(image)\n",
    "    words = []\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,thresh_index,255,cv2.THRESH_BINARY_INV)\n",
    "    #show(thresh)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE )\n",
    "    #sort contours\n",
    "    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    resulted_rectangles = get_rectangles_from_contours(sorted_ctrs, h_img, w_img)\n",
    "    \n",
    "    # Show how resulted contours will be selected at image\n",
    "    for rect in resulted_rectangles:\n",
    "        cv2.rectangle(thresh,(rect.x,rect.y),( rect.x + rect.w, rect.y + rect.h ),(255,255,255),2)\n",
    "    show(thresh)\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    image_to_cut = img[40:h_img-40, 40:w_img-40]\n",
    "    \n",
    "    #Add words into array\n",
    "    for rect in resulted_rectangles:\n",
    "        roi = image_to_cut.copy()[rect.y:rect.y+rect.h, rect.x:rect.x+rect.w]\n",
    "        words.append(roi)\n",
    "        \n",
    "    return words\n",
    "    \n",
    "    #words.sort(key = sort_w, reverse = True)\n",
    "    #res_words = []\n",
    "    #for i, word in enumerate(words):\n",
    "    #       res_words.append(word)\n",
    "    #return res_words\n",
    "    \n",
    "def resulted_function(img_path, author, path_to_save):\n",
    "    count_written = 0\n",
    "    img = cv2.imread(img_path)\n",
    "    #index1 = img_path.index('/')+1\n",
    "    #index2 = img_path.index('.')\n",
    "    #author = img_path[index1:index2]\n",
    "    \n",
    "    h_img, w_img, _ = img.shape\n",
    "    # Get optimal binarization index\n",
    "    res_index = compare_thresh_indexes(img)\n",
    "    print('res_index ' + str(res_index))\n",
    "    \n",
    "    contours = contours_extraction(img_path, res_index)\n",
    "    for i, contour in enumerate(contours):\n",
    "        h, w, _ = contour.shape\n",
    "        binary_contour = get_thresh_image(contour, res_index)\n",
    "        percent = percent_of_white_pixels_word(binary_contour)\n",
    "\n",
    "        if 0.7 <= percent <= 0.95 :\n",
    "            print('contour № ' + str(i))\n",
    "            show(binary_contour)\n",
    "            try:\n",
    "                if h >=  w/5 or w <= w_img / 15:\n",
    "                    words = prepare_binary_contour(binary_contour)\n",
    "                    #if lines is not None:\n",
    "                        #words = extract_words(lines)\n",
    "                    for k, word in enumerate(words):\n",
    "                        try:\n",
    "                            h_lw, w_lw = word.shape\n",
    "                            if h_lw >= h/4:\n",
    "                                path = path_to_save + '/' + author + '_' + 'word_' + str(i) + str(k) + '.png'\n",
    "                                cv2.imwrite(path, word) \n",
    "                                count_written += 1\n",
    "                        except:\n",
    "                            path = path_to_save + '/' + author + '_' + 'word_' + str(i)+ '.png'\n",
    "                            cv2.imwrite(path,binary_contour) \n",
    "                            count_written += 1\n",
    "                else:\n",
    "                    path = path_to_save + '/' + author + '_' + 'word_'+ str(i) + '.png'\n",
    "                    cv2.imwrite(path,binary_contour) \n",
    "                    count_written += 1\n",
    "            except (ZeroDivisionError, statistics.StatisticsError):\n",
    "                path = path_to_save + '/' + author + '_' + 'word_'+ str(i) + '.png'\n",
    "                cv2.imwrite(path,binary_contour) \n",
    "                count_written += 1\n",
    "\n",
    "        #path = path_to_save + '/' + author + '_' + 'word_' + str(i)+ '.png'\n",
    "       # cv2.imwrite(path,binary_contour) \n",
    "    print(len(contours))\n",
    "\n",
    "def create_csv_file(words_path, words_csv):\n",
    "    names = []\n",
    "    authors = []\n",
    "    for word_file in os.listdir(words_path):\n",
    "        label =  word_file[:word_file.find('word' )-1]\n",
    "        names.append(word_file)\n",
    "        authors.append(label)\n",
    "    pd.DataFrame({\"file_name\": names, \"label\": authors}) \\\n",
    "            .to_csv(words_csv, index=False, header=True, columns = [\"file_name\", \"label\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function should be used to classify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_photo(path_to_photo, train_words, test_words, train_csv, test_csv, cache_dir, embeddings, \n",
    "                  weights, names_xlsx):\n",
    "    \n",
    "    img_name = 'author' +  str(random.randint(0, 100000))\n",
    "    resulted_function(path_to_photo, img_name, path_to_test_words)\n",
    "    \n",
    "    create_csv_file(test_words, test_csv)\n",
    "    create_csv_file(train_words, train_csv)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(cache_dir)\n",
    "    except OSError: \n",
    "        print('')\n",
    "    \n",
    "    model = TripletModel(alpha=0.75, input_shape=(160, 160, 3), cache_dir=cache_dir)\n",
    "    model.load_weights(weights)\n",
    "    #model.make_embeddings('train_words', 'train.csv', embeddings,  batch_size=32)\n",
    "    model.load_embeddings(embeddings)\n",
    "    model.make_embeddings(train_words, train_csv, embeddings, batch_size=1)\n",
    "    \n",
    "    d = {}\n",
    "    result = model.predict(test_words, test_csv, author_tested, batch_size=1)\n",
    "    \n",
    "    names = pd.read_excel(names_xls, sheet_name=None)\n",
    "    for i, id in enumerate(names['Лист1']['Identifier']):\n",
    "        if id in (result):\n",
    "            d[id] = names['Лист1']['Author'][i]\n",
    "\n",
    "    for key in d.keys():\n",
    "        print(d[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_photo = 'Test photo/test_photo.png'\n",
    "\n",
    "train_words = 'Test photo/train_words'\n",
    "test_words = 'Test photo/test_words'\n",
    "\n",
    "train_csv = 'Test photo/train.csv'\n",
    "test_csv = 'Test photo/test.csv'\n",
    "\n",
    "cache_dir = 'Test photo/triplet_cache'\n",
    "\n",
    "embeddings = 'Test photo/embeddings.pkl'\n",
    "weights = 'Test photo/final_weights.h5'\n",
    "\n",
    "names_xls = 'Test photo/Autors_and_numbers.xlsx'\n",
    "\n",
    "classify_photo(path_to_photo, train_words, test_words, train_csv, test_csv, cache_dir, embeddings, \n",
    "                  weights, names_xls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
