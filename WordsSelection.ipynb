{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words selection from handwriting documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import plot\n",
    "    \n",
    "from statistics import mean\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    \"\"\"\n",
    "    show rgb image\n",
    "    \"\"\"\n",
    "    ax = plt.axes([0,0,4,4], frameon=False)\n",
    "    ax.set_axis_off()\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "def show_gray(img):\n",
    "    \"\"\"\n",
    "    show grayscale image\n",
    "    \"\"\"\n",
    "    ax = plt.axes([0,0,4,4], frameon=False)\n",
    "    ax.set_axis_off()\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_words(path, words):\n",
    "    for i, word in enumerate(words):\n",
    "        cv2.imwrite(os.path.join(path , 'word_' + str(i) + '.png'), word)\n",
    "        \n",
    "def sort_w(word):\n",
    "    shape = word.shape\n",
    "    return shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class that helps to find where one contours are inside others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RECT:\n",
    "\n",
    "    def __init__(self, x, y, h,  w):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "def contains(R1,  R2):\n",
    "    if ((R2.x+R2.w) < (R1.x+R1.w)) and ((R2.x) > (R1.x)) and ((R2.y) > (R1.y)) and ((R2.y+R2.h) < (R1.y+R1.h)):\n",
    "            return True;\n",
    "    else:\n",
    "        return False;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that helps to improve binarization index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_of_white_pixels_word(thresh):\n",
    "    white_pixels = 0\n",
    "    h, w, = thresh.shape\n",
    "    for i in range (h):\n",
    "        for j in range (w):\n",
    "            if (thresh[i][j] == 255):\n",
    "                white_pixels += 1\n",
    "\n",
    "    all_pixels = h *  w\n",
    "    return (round(white_pixels/all_pixels, 2))\n",
    "\n",
    "def percent_of_white_pixels(img, thresh_index):\n",
    "    print(\"thresh_index\" + str(thresh_index))\n",
    "    h, w, _ = img.shape\n",
    "    image = img[40:h-40, 40:w-40]\n",
    "    show(image)\n",
    "    words = []\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,thresh_index,255,cv2.THRESH_BINARY_INV)\n",
    "    white_pixels = 0\n",
    "    show(thresh)\n",
    "    h, w, = thresh.shape\n",
    "    for i in range (h):\n",
    "        for j in range (w):\n",
    "            if (thresh[i][j] == 255):\n",
    "                white_pixels += 1\n",
    "\n",
    "    all_pixels = h *  w\n",
    "    return (round(white_pixels/all_pixels, 2))\n",
    "\n",
    "        \n",
    "def compare_thresh_indexes(img):\n",
    "    thresh_indexes = [ 127, 147, 167, 187 ]\n",
    "    dict_with_norm_white_percent = {}\n",
    "    dict_with_big_white_percent = {}\n",
    "    best_percent = 100\n",
    "    best_index = 0\n",
    "    best_val = 100\n",
    "    d1 = {}\n",
    "    d2 = {}\n",
    "    for index in thresh_indexes:\n",
    "        percent = percent_of_white_pixels(img, index)\n",
    "        if percent >= 0.01 and percent <= 0.15:\n",
    "            dict_with_norm_white_percent[index] = percent\n",
    "            print(\"index \" + str(index) + \" - \" + str(percent))\n",
    "        else:\n",
    "            dict_with_big_white_percent[index] = percent\n",
    "    if len(dict_with_norm_white_percent) == 0:\n",
    "        for index in dict_with_big_white_percent.keys():\n",
    "            if dict_with_big_white_percent[index] <= best_percent:\n",
    "                best_percent = dict_with_big_white_percent[index]\n",
    "                best_index = index\n",
    "            \n",
    "    else:\n",
    "        for index in dict_with_norm_white_percent.keys():\n",
    "            new_value = math.fabs(dict_with_norm_white_percent[index] - 0.07)\n",
    "            if new_value <= best_val:\n",
    "                best_val = new_value\n",
    "                best_percent = dict_with_norm_white_percent[index]\n",
    "                best_index = index\n",
    "    print(\"best index = \" + str(index) + \" - best_percent = \" + str(best_percent))\n",
    "    return index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that helps to select words from too big contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresh_image(img, index):\n",
    "    if len(img.shape) == 3:\n",
    "        h, w, _  = img.shape\n",
    "    else:\n",
    "        h, w  = img.shape\n",
    "    contour = [0, 0, w, h]\n",
    "    binary = cv2.cvtColor(img.copy(), cv2.COLOR_RGB2GRAY)\n",
    "    show_gray(binary)\n",
    "    ret,thresh = cv2.threshold(binary,index,255,cv2.THRESH_BINARY)\n",
    "    show(thresh)\n",
    "    return thresh\n",
    "\n",
    "def get_chunks(image, channels = 1):\n",
    "    \"\"\"\n",
    "    Split image on chunks, each chunk is 5 percent of image width\n",
    "    return: array with y-coordinates\n",
    "    \"\"\"\n",
    "    n, m = image.shape\n",
    "    return np.arange(0, m + 1, m // 20)\n",
    "\n",
    "def prepare_thresh(thresh1):\n",
    "    hists, average_black_height, average_white_height, lines_count = build_hists(thresh1)\n",
    "\n",
    "    sm_hists = smooth_hists(hists)\n",
    "    show_hists(sm_hists)\n",
    "    valleys = find_valleys(sm_hists)\n",
    "    show_valleys(thresh1, valleys)\n",
    "    lines, avg_height = get_lines(thresh1, valleys) \n",
    "\n",
    "    show_lines(thresh1, lines)\n",
    "    lines = filter_chunks(lines, average_black_height, average_white_height)\n",
    "\n",
    "    show_lines(thresh1, lines)\n",
    "    created_lines = get_first_approach_lines(lines, average_black_height)\n",
    "    draw_lines(thresh1, created_lines)\n",
    "\n",
    "    created_lines = sorted(created_lines, key = lambda x: x.data[0].y)\n",
    "    draw_lines(thresh1, created_lines)\n",
    "    extracted_lines = cut_lines(thresh1, created_lines)\n",
    "    return extracted_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical functions to improve words extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN = (0, 255, 0)\n",
    "BLUR = (255, 0, 0)\n",
    "RED = (0, 0, 255)\n",
    "    \n",
    "def find_text_contours(image):\n",
    "    \"\"\"\n",
    "    Find areas with text on image\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "    n, m, _ = img.shape\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "    # gray = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)[1]\n",
    "    show_gray(gray)\n",
    "    binary = cv2.bitwise_not(gray)\n",
    "    show_gray(binary)\n",
    "    contours, hierarchy  = cv2.findContours(binary,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    text_contours = []\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if m > w > m / 2 and n / 2 > h > n / 12:\n",
    "            text_contours.append([x, y, w, h])\n",
    "    text_contours.sort(key = lambda x : x[1])\n",
    "    return text_contours\n",
    "\n",
    "\n",
    "def draw_contour_on_image(image, contours):\n",
    "    \"\"\"\n",
    "    Draw contours finded with function \"find_text_contours\"\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cnt\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), GREEN, 4)\n",
    "    show(img)\n",
    "    \n",
    "def get_text_area(image, contour, padding = 20):\n",
    "    \"\"\"\n",
    "    Cut text areas from image with contours find in \"find_text_contours\"\n",
    "    \"\"\"\n",
    "    x, y, w, h = contour\n",
    "    img = image[y + padding +10  : y + h - padding - 10, x + padding + 10 : x + w - padding - 80]\n",
    "    return cv2.copyMakeBorder(img, 5, 5, 5, 5, cv2.BORDER_CONSTANT, value=[255,255,255] )\n",
    "\n",
    "def otsu_binarization(image):\n",
    "    \"\"\"\n",
    "    Otsu image binarization\n",
    "    \"\"\"\n",
    "    img = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2GRAY)\n",
    "    img = cv2.threshold(img, 230, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "    return img\n",
    "\n",
    "def get_chunks(image, channels = 1):\n",
    "    \"\"\"\n",
    "    Split image on chunks, each chunk is 5 percent of image width\n",
    "    return: array with y-coordinates\n",
    "    \"\"\"\n",
    "    if (channels == 3):\n",
    "        n, m, _ = image.shape\n",
    "    else:\n",
    "        n, m = image.shape\n",
    "    return np.arange(0, m + 1, m // 20)\n",
    "\n",
    "def median_smooth(signal, kernel_size = 5):\n",
    "    \"\"\"\n",
    "    Smooth signal\n",
    "    \"\"\"\n",
    "    smooth_signal = []\n",
    "    for i, val in enumerate(signal[:-kernel_size]):\n",
    "        smooth_signal.append(sum(signal[i: i + kernel_size]) / kernel_size)\n",
    "        #smooth_signal.append(np.median(signal[i: i + kernel_size]))\n",
    "    return np.array(smooth_signal)\n",
    "\n",
    "def build_hists(image):\n",
    "    \"\"\"\n",
    "    Build hist to each chunk\n",
    "    \"\"\"\n",
    "    hists = []\n",
    "    chunks = get_chunks(image)\n",
    "    black_height = []\n",
    "    white_height = []\n",
    "    lines_count = []\n",
    "    for i, val in enumerate(chunks[:-1]):\n",
    "        chunk = image[:, val : chunks[i + 1]]\n",
    "        hist = np.sum(1 - (chunk / 255), axis=1)\n",
    "        current_black_height = 0\n",
    "        current_white_height = 0\n",
    "        count = 0\n",
    "        if hist[0] == 0:\n",
    "            current_black_height += 1\n",
    "        else:\n",
    "            current_white_height += 1\n",
    "        for pix in hist[1:]:\n",
    "            if pix == 0:\n",
    "                if current_black_height > 0:\n",
    "                    current_black_height += 1\n",
    "                else:\n",
    "                    current_black_height += 1\n",
    "                    white_height.append(current_white_height)\n",
    "                    current_white_height = 0\n",
    "            else:\n",
    "                if current_white_height > 0:\n",
    "                    current_white_height += 1\n",
    "                else:\n",
    "                    current_white_height += 1\n",
    "                    black_height.append(current_black_height)\n",
    "                    count += 1\n",
    "                    current_black_height = 0\n",
    "        lines_count.append(count)\n",
    "        hists.append(hist)\n",
    "    print('avg_black_height ' + str(mean(black_height)))\n",
    "    print('avg_white_height ' + str(mean(white_height)))\n",
    "    return hists, mean(black_height), mean(white_height), lines_count\n",
    "\n",
    "def smooth_hists(hists):\n",
    "    \"\"\"\n",
    "    Smooth hists witch is got in function build_hists\n",
    "    \"\"\"\n",
    "    new_hists = []\n",
    "    for hist in hists:\n",
    "        new_hists.append(median_smooth(hist))\n",
    "    return new_hists\n",
    "\n",
    "def show_hists(hists):\n",
    "    \"\"\"\n",
    "    Draw hists\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    y = np.arange(len(hists[0]))\n",
    "    for i in range(len(hists)):\n",
    "        h = hists[i]\n",
    "        plt.plot(h[::-1] + i*35, y)\n",
    "    ax = plt.axes([0,0,1,1], frameon=False)\n",
    "    ax.set_axis_off()\n",
    "    plt.show()\n",
    "    fig.savefig('temp.png', dpi=fig.dpi)\n",
    "#     axes = []    \n",
    "#     fig, axes = plt.subplots(nrows=1, ncols=len(hists), figsize=(20, 20))\n",
    "#     y = np.arange(len(hists[0]))\n",
    "#     for i in range(len(hists)):\n",
    "#         h = hists[i]\n",
    "#         axes[i].plot(h[::-1], y)\n",
    "#     plt.show()\n",
    "    \n",
    "def chunks_on_image(image, chunks):\n",
    "    \"\"\"\n",
    "    Draw chunks on image\n",
    "    \"\"\"\n",
    "    text_chunks = image.copy()\n",
    "    n, m, _ = text_chunks.shape\n",
    "    for i in chunks:\n",
    "        cv2.line(text_chunks, (i, 0), (i, n),GREEN,3)\n",
    "    show(text_chunks)\n",
    "    \n",
    "\n",
    "def find_valleys(sm_hists, thresh = 1):\n",
    "    \"\"\"\n",
    "    Поиск впадин на сглаженных гистограммах \n",
    "    \"\"\"\n",
    "    valleys = []\n",
    "    interval_average_height = []\n",
    "    for curr in sm_hists:\n",
    "        curr[curr < thresh] = 0\n",
    "        valleys_ind, curr_valley = [], []\n",
    "        prev = 1\n",
    "        for i, val in enumerate(curr[:-1]):\n",
    "            if (val == 0 and prev != 0):\n",
    "                curr_valley.append(i)\n",
    "            if (val == 0 and curr[i + 1] != 0):\n",
    "                curr_valley.append(i)\n",
    "            if len(curr_valley) == 2:\n",
    "                valleys_ind.append(curr_valley)\n",
    "                interval_average_height.append(curr_valley[1] - curr_valley[0])\n",
    "                curr_valley = []\n",
    "            if len(curr_valley) == 1 and (i == len(curr) - 2):\n",
    "                curr_valley.append(i)\n",
    "                valleys_ind.append(curr_valley)\n",
    "            prev = val\n",
    "        valleys.append(valleys_ind)\n",
    "    return valleys\n",
    "\n",
    "\n",
    "def show_valleys(image, valleys, channels = 3):\n",
    "    chunks = get_chunks(image, channels)\n",
    "    img = image.copy()\n",
    "    \n",
    "    for i, y in enumerate(chunks[:-1]):\n",
    "        for (x_1, x_2) in valleys[i]:\n",
    "            cv2.line(img, (y, x_1), (chunks[i + 1], x_1),GREEN,3)\n",
    "            cv2.line(img, (y, x_2), (chunks[i + 1], x_2),RED,3)\n",
    "    if channels == 3:\n",
    "        show(img)\n",
    "    else:\n",
    "        show_gray(img)\n",
    "\n",
    "class Trait:\n",
    "    \"\"\"\n",
    "    Класс штрих\n",
    "    \"\"\"\n",
    "    def __init__(self, x_1, x_2, y_1):\n",
    "        self.x_1 = x_1\n",
    "        self.x_2 = x_2\n",
    "        self.y_1 = y_1\n",
    "        #self.y_2 = y_2\n",
    "    \n",
    "    def dist(self, other):\n",
    "        return ((self.x_2 - other.x_1) ** 2 + (self.y_1 - other.y_1) ** 2) ** (1 / 2)\n",
    "    \n",
    "    def print_(self):\n",
    "        print('x_1: {}  x_2: {}  y: {}'.format(self.x_1, self.x_2, self.y_1))\n",
    "    \n",
    "    \n",
    "def get_lines(image, valleys, channels = 3):\n",
    "    \"\"\"\n",
    "    Вычислить среднюю линию в впадине и среднюю высоту строки\n",
    "    \"\"\"\n",
    "    #h, w, _ = image.shape\n",
    "    #image = image[10:h-10, 10:w - 10]\n",
    "    total_lines = []\n",
    "    chunks = get_chunks(image, channels)\n",
    "    for i, chunk in enumerate(chunks[:-1]):\n",
    "        chunk_lines = []\n",
    "        for val in valleys[i]:\n",
    "            chunk_lines.append(Trait(chunk, chunks[i+1], sum(val) // len(val)))\n",
    "        total_lines.append(chunk_lines)\n",
    "    \n",
    "    height = []\n",
    "    for i, line in enumerate(total_lines):\n",
    "        for j, trait in enumerate(line[:-1]):\n",
    "            height.append(abs(trait.y_1 - line[j + 1].y_1))\n",
    "            #print('line ' + str(i) + ' = ' + str((abs(trait.y_1 - line[j + 1].y_1))))\n",
    "    height = sum(height) / len(height)\n",
    "    #print('height = ' + str(height))\n",
    "    return total_lines, height\n",
    "\n",
    "def show_lines(image, lines):\n",
    "    img = image.copy()\n",
    "    for chunk in lines:\n",
    "        for line in chunk:\n",
    "            cv2.line(img, (line.x_1, line.y_1), (line.x_2, line.y_1),GREEN,3)\n",
    "    show(img)\n",
    "    \n",
    "    \n",
    "Point = namedtuple('Point', ['x' , 'y'])\n",
    "# class Point:\n",
    "#     def __init__(self, x, y):\n",
    "#         self.x = x\n",
    "#         self.y = y\n",
    "\n",
    "class Line:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.last_trait = None\n",
    "        \n",
    "    def continue_line(self, trait):\n",
    "        self.data.append(Point(trait.x_1, trait.y_1))\n",
    "        self.data.append(Point(trait.x_2, trait.y_1))\n",
    "\n",
    "        \n",
    "def filter_chunk(chunk, avg_black_height, average_white_height):\n",
    "    prev = chunk[0]\n",
    "    new_traits = [prev]\n",
    "    for i, trait in enumerate(chunk[1:-1]):\n",
    "        next_trait = chunk[i + 2]\n",
    "        if abs(prev.y_1 - trait.y_1) > (avg_black_height + average_white_height/4) \\\n",
    "            and abs(next_trait.y_1 - trait.y_1) > (avg_black_height+ average_white_height/4):\n",
    "            new_traits.append(trait)\n",
    "            prev = trait\n",
    "    new_traits.append(chunk[-1])\n",
    "    return new_traits\n",
    "\n",
    "def filter_chunks(chunks, avg_black_height, average_white_height):\n",
    "    new_chunks = []\n",
    "    for chunk in chunks:\n",
    "        new_chunks.append(filter_chunk(chunk, avg_black_height, average_white_height))\n",
    "    return new_chunks\n",
    "            \n",
    "    \n",
    "def connect_two_chunks(chunk_1, chunk_2, avg_height):\n",
    "    \"\"\"\n",
    "    Соединить первые две chunk-ки\n",
    "    \"\"\"\n",
    "    all_inds_from_chunk2 = [i for i in range(len(chunk_2))]\n",
    "    used_traits_from_chunk2 = []\n",
    "    created_lines = []\n",
    "    for trait_1 in chunk_1:\n",
    "        minimum = sys.maxsize\n",
    "        for j, trait_2 in enumerate(chunk_2):\n",
    "            if trait_1.dist(trait_2) <  minimum:\n",
    "                minimum = trait_1.dist(trait_2)\n",
    "                min_trait = trait_2\n",
    "            #if minimum >= avg_height / 2:\n",
    "            if minimum >= 2 * avg_height / 3:\n",
    "                min_trait = Trait(min_trait.x_1, min_trait.x_2, trait_1.y_1)\n",
    "                \n",
    "            if (min_trait.x_1 == trait_2.x_1) and (min_trait.x_2 == trait_2.x_2) \\\n",
    "                and (min_trait.y_1 == trait_2.y_1):\n",
    "                used_traits_from_chunk2.append(j)\n",
    "        new_line = Line()\n",
    "        new_line.continue_line(trait_1)\n",
    "        new_line.continue_line(min_trait)\n",
    "        new_line.last_trait = min_trait\n",
    "        created_lines.append(new_line)\n",
    "    unused_traits = list(set(all_inds_from_chunk2) - set(used_traits_from_chunk2))\n",
    "\n",
    "    for trait in unused_traits:\n",
    "        chunk = chunk_2[trait]\n",
    "        new_line = Line()\n",
    "        start_trait = Trait(chunk_1[0].x_1, chunk.x_1, chunk.y_1)\n",
    "        new_line.continue_line(start_trait)\n",
    "        new_line.continue_line(chunk)\n",
    "        new_line.last_trait = chunk\n",
    "        created_lines.append(new_line)\n",
    "    return created_lines\n",
    "    \n",
    "def connect_start_lines_with_next_chunks(lines, chunk, avg_height):\n",
    "    all_inds_from_chunk = [i for i in range(len(chunk))]\n",
    "    used_traits_from_chunk = []\n",
    "    for line in lines:\n",
    "        trait_1 = line.last_trait\n",
    "        minimum = sys.maxsize\n",
    "        for j, trait_2 in enumerate(chunk):\n",
    "            if trait_1.dist(trait_2) <  minimum:\n",
    "                minimum = trait_1.dist(trait_2)\n",
    "                min_trait = trait_2\n",
    "            if minimum >= avg_height / 2.0:\n",
    "                min_trait = Trait(min_trait.x_1, min_trait.x_2, trait_1.y_1)\n",
    "                \n",
    "            if (min_trait.x_1 == trait_2.x_1) and (min_trait.x_2 == trait_2.x_2) \\\n",
    "                and (min_trait.y_1 == trait_2.y_1):\n",
    "                used_traits_from_chunk.append(j)\n",
    "        line.continue_line(min_trait)\n",
    "        line.last_trait = min_trait\n",
    "    unused_traits = list(set(all_inds_from_chunk) - set(used_traits_from_chunk))\n",
    "    print(unused_traits)\n",
    "    for i in unused_traits:\n",
    "        trait = chunk[i]\n",
    "        start_trait = Trait(0, trait.x_1, trait.y_1)\n",
    "        new_line = Line()\n",
    "        new_line.continue_line(start_trait)\n",
    "        new_line.continue_line(trait)\n",
    "        new_line.last_trait = trait\n",
    "        lines.append(new_line)\n",
    "        \n",
    "def connect_lines_with_chunk(lines, chunk, avg_height):\n",
    "    \"\"\"\n",
    "    Соединить оставшиеся chunk-ки и уже созданные линии\n",
    "    \"\"\"\n",
    "    for line in lines: \n",
    "        trait_1 = line.last_trait\n",
    "        minimum = sys.maxsize\n",
    "        if len(chunk) == 0:\n",
    "            return\n",
    "        for trait_2 in chunk:\n",
    "            if trait_1.dist(trait_2) <  minimum:\n",
    "                minimum = trait_1.dist(trait_2)\n",
    "                min_trait = trait_2\n",
    "            if minimum >=  avg_height / 1:\n",
    "            \n",
    "                min_trait = Trait(min_trait.x_1, min_trait.x_2, trait_1.y_1)\n",
    "        line.continue_line(min_trait)\n",
    "        line.last_trait = min_trait\n",
    "\n",
    "def get_first_approach_lines(chunk_with_traits, avg_height):\n",
    "    \"\"\"\n",
    "    Get first approach of splitting lines\n",
    "    \"\"\"\n",
    "    created_lines = connect_two_chunks(chunk_with_traits[0], chunk_with_traits[1], avg_height)\n",
    "    connect_start_lines_with_next_chunks(created_lines, chunk_with_traits[2], avg_height)\n",
    "    for chunk in chunk_with_traits[3:]:\n",
    "        connect_lines_with_chunk(created_lines, chunk, avg_height)\n",
    "    #print('avg height = ' + str(avg_height))\n",
    "    return created_lines\n",
    "\n",
    "\n",
    "def draw_line(image, line):\n",
    "    img = image.copy()\n",
    "    color = [random.randint(0, 255) for _ in range(3)]\n",
    "    for i, point in enumerate(line.data[:-1]):\n",
    "        next_point = line.data[i + 1]\n",
    "        cv2.line(img, (point.x, point.y), (next_point.x, next_point.y), color ,3)\n",
    "        #print('height = ' + str(next_point.y - point.y))\n",
    "    return img\n",
    "    \n",
    "def draw_lines(image, lines, channels = 3):\n",
    "    \"\"\"\n",
    "    Draw splitting lines\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "    for line in lines:\n",
    "        img = draw_line(img, line)\n",
    "    if channels == 3:\n",
    "        cv2.imwrite(\"12345.png\", img)\n",
    "        show(img)\n",
    "    else:\n",
    "        show_gray(img)\n",
    "    \n",
    "\n",
    "def cut_line(image, line_1, line_2):\n",
    "    \n",
    "    n, m = image.shape\n",
    "    print('')\n",
    "    print('n = ' + str(n))\n",
    "    print('m = ' + str(m))\n",
    "    img = image.copy()\n",
    "    x_list = []\n",
    "    for i, point in enumerate(line_1.data[:-1]):\n",
    "        next_point = line_1.data[i + 1]\n",
    "        img[:point.y, point.x:next_point.x] = 255\n",
    "        x_list.append(point.x)\n",
    "    for i, point in enumerate(line_2.data[:-1]):\n",
    "        next_point = line_2.data[i + 1]\n",
    "        img[point.y:n, point.x:next_point.x] = 255\n",
    "        x_list.append(point.x)\n",
    "    max_x = max(x_list)\n",
    "    print('max_x = ' + str(max_x))\n",
    "    img[:, max_x:m] = 255\n",
    "#line1: [Point(x=0, y=111), Point(x=88, y=111)\n",
    "    inds = np.argwhere(img == 0)\n",
    "    if len(inds) != 0:\n",
    "        x_min = min(inds[:, 0])\n",
    "        x_max = max(inds[:, 0])\n",
    "        y_min = min(inds[:, 1])\n",
    "        y_max = max(inds[:, 1])\n",
    "        show_gray(img[x_min:x_max,:])\n",
    "        #cv2.imwrite('line' + str(random.randint(0, 100)) + '.png', img[x_min:x_max,:])\n",
    "        return img[x_min:x_max, y_min:y_max]\n",
    "        \n",
    "\n",
    "def cut_lines(image, created_lines):\n",
    "    lines = []\n",
    "    for i, line in enumerate(created_lines[:-1]):\n",
    "        #print('line1: ' + str(line.data))\n",
    "        #print('line2: ' + str( created_lines[i + 1].data))\n",
    "        lines.append(cut_line(image, line, created_lines[i + 1]))\n",
    "        #print('avg_height = ' + str(sum(line.data.y))/len(line.data.y))\n",
    "    return lines\n",
    "    \n",
    "def upwords_traversal(img, point):\n",
    "    \"\"\"\n",
    "    обход снизу вверх\n",
    "    \"\"\"\n",
    "    points = [point]\n",
    "    min_point = point\n",
    "    n, m = img.shape\n",
    "    used_points = []\n",
    "    while len(points) > 0:\n",
    "        next_point = points.pop(0)\n",
    "        used_points.append(next_point)\n",
    "        #проверяем, что не выходим за границы изображения\n",
    "        neighbors = []\n",
    "        if (0 < next_point.x + 1 < m) and (0 < next_point.y + 1 < n) \\\n",
    "            and (0 <= next_point.x - 1 <= m) and (0 <= next_point.y - 1 <= n):\n",
    "            neighbors += [Point(next_point.x - 1, next_point.y - 1), Point(next_point.x, next_point.y - 1)]\n",
    "            neighbors += [Point(next_point.x + 1, next_point.y - 1), Point(next_point.x + 1, next_point.y)]\n",
    "        for p in neighbors:\n",
    "            if img[p.y, p.x] == 0:\n",
    "                if (p not in points) and (p not in used_points):\n",
    "                    points.append(p)\n",
    "                if p.y < min_point.y:\n",
    "                    min_point = p\n",
    "    return min_point\n",
    "        \n",
    "    \n",
    "def downwords_traversal(img, point):\n",
    "    \"\"\"\n",
    "    обход сверху сниз\n",
    "    \"\"\"\n",
    "    points = [point]\n",
    "    max_point = point\n",
    "    n, m = img.shape\n",
    "    used_points = []\n",
    "    while len(points) > 0:\n",
    "        next_point = points.pop(0)\n",
    "        used_points.append(next_point)\n",
    "        #проверяем, что не выходим за границы изображения\n",
    "        neighbors = []\n",
    "        if (0 < next_point.x + 1 < m) and (0 < next_point.y + 1 < n) \\\n",
    "            and (0 <= next_point.x - 1 <= m) and (0 <= next_point.y - 1 <= n):\n",
    "            neighbors += [Point(next_point.x - 1, next_point.y + 1), Point(next_point.x, next_point.y + 1)]\n",
    "            neighbors += [Point(next_point.x + 1, next_point.y + 1), Point(next_point.x + 1, next_point.y)]\n",
    "        for p in neighbors:\n",
    "            if img[p.y, p.x] == 0:\n",
    "                if (p not in points) and (p not in used_points):\n",
    "                    points.append(p)\n",
    "                if p.y > max_point.y:\n",
    "                    max_point = p\n",
    "    return max_point\n",
    "\n",
    "def adjust_lines(binary, created_lines, average_black_height):\n",
    "    img = binary.copy()\n",
    "    for line_data in created_lines:\n",
    "        line = line_data.data\n",
    "        new_line = []\n",
    "        for i, point_1 in enumerate(line[:-1]):\n",
    "            point_2 = line[i+1]\n",
    "            trait = img[point_1.y, point_1.x:point_2.x]\n",
    "            start_black = 0\n",
    "            for i in range(len(trait)):\n",
    "                if trait[i] == 0:\n",
    "                    start_black = i  \n",
    "                    break\n",
    "            if start_black:\n",
    "                x = start_black + point_1.x\n",
    "                y = point_1.y\n",
    "                top = upwords_traversal(img, Point(x, y))\n",
    "                bottom = downwords_traversal(img, Point(x, y))\n",
    "                h_u = abs(y - top.y)\n",
    "                h_d = abs(y - bottom.y)\n",
    "                if h_u < h_d and h_u <= average_black_height:\n",
    "                    new_line.append(Point(point_1.x, top.y))\n",
    "                    new_line.append(Point(point_2.x, top.y))\n",
    "                elif h_d < h_u and h_d <= average_black_height:\n",
    "                    new_line.append(Point(point_1.x, bottom.y))\n",
    "                    new_line.append(Point(point_2.x, bottom.y))\n",
    "                else:\n",
    "                    new_line.append(point_1)\n",
    "            else:\n",
    "                new_line.append(point_1)\n",
    "        print(new_line)\n",
    "        new_line.append(line[-1])\n",
    "        line_data.data = new_line\n",
    "        \n",
    "        \n",
    "\n",
    "def get_words_from_line(line, min_width = 10, thresh =  100): #400000\n",
    "    \"\"\"\n",
    "    line : grayscale line\n",
    "    min_width : min space length\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    if line is None:\n",
    "        return words\n",
    "    n, m = line.shape\n",
    "    image = cv2.bitwise_not(line)\n",
    "    y = np.sum(image // 255, axis = 0)\n",
    "    #x = np.arange(len(y))\n",
    "    #plot(x, y)\n",
    "    #plt.show()\n",
    "\n",
    "    _, inds = np.where([y == 0])\n",
    "\n",
    "    start = 0\n",
    "    spaces = []\n",
    "    for i, ind in enumerate(inds[:-1]):\n",
    "        if (ind + 1 == inds[i + 1]) and (start == 0):\n",
    "            start = ind\n",
    "        elif (ind + 1 < inds[i + 1]) and (start != 0):\n",
    "            if (ind - start) >= min_width:\n",
    "                spaces.append([int(start), int(ind)])\n",
    "                start = 0\n",
    "            else:\n",
    "                start = 0\n",
    "\n",
    "    spaces = np.ravel(spaces)\n",
    "    spaces = np.insert(spaces, [0, len(spaces)], [0, m])\n",
    "    spaces = spaces.reshape(len(spaces) // 2, 2)     \n",
    "    \n",
    "    for inds in spaces:\n",
    "        word = line[:, int(inds[0]): int(inds[1])]\n",
    "        print(\"sum\", np.sum(word))\n",
    "        show_gray(word)\n",
    "        if np.sum(1 - (word / 255)) > thresh:\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "def extract_words(lines):\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        words += get_words_from_line(line)\n",
    "    return words\n",
    "\n",
    "def save_words(path, words):\n",
    "    for i, word in enumerate(words):\n",
    "        cv2.imwrite(os.path.join(path , 'word_' + str(i) + '.png'), word)\n",
    "        \n",
    "def sort_w(word):\n",
    "    shape = word.shape\n",
    "    return shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulted function to prepare an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_words_extraction(img_path, thresh_index):\n",
    "    img = cv2.imread(img_path)\n",
    "    h_img, w_img, _ = img.shape\n",
    "    image = img[40:h_img-40, 40:w_img-40]\n",
    "    #show(image)\n",
    "    words = []\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,thresh_index,255,cv2.THRESH_BINARY_INV)\n",
    "    #show(thresh)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE )\n",
    "    #sort contours\n",
    "    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    rectangles = []\n",
    "    for i, ctr in enumerate(sorted_ctrs):\n",
    "        # Get bounding box\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        if w >= w_img/50 and h >= h_img/50 and w <= w_img/2 and h <= h_img/10:\n",
    "            r = RECT(x,y,h, w)\n",
    "            rectangles += [r]\n",
    "    resultedRectangles = []\n",
    "    for i in range (len(rectangles)):\n",
    "        isSmall = True\n",
    "        r1 = rectangles[i]\n",
    "        for j in range(i+1, len(rectangles)):\n",
    "            r2 = rectangles[j]\n",
    "            if (contains(r1, r2)):\n",
    "                isSmall = False       \n",
    "        if isSmall:\n",
    "            resultedRectangles += [r1]\n",
    "    for rect in resultedRectangles:\n",
    "        cv2.rectangle(thresh,(rect.x,rect.y),( rect.x + rect.w, rect.y + rect.h ),(255,255,255),2)\n",
    "    show(thresh)\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    h_img, w_img, _ = img.shape\n",
    "    image_to_cut = img[40:h_img-40, 40:w_img-40]\n",
    "    for rect in resultedRectangles:\n",
    "        roi = image_to_cut.copy()[rect.y:rect.y+rect.h, rect.x:rect.x+rect.w]\n",
    "        words.append(roi)\n",
    "    \n",
    "    words.sort(key = sort_w, reverse = True)\n",
    "    res_words = []\n",
    "    for i, word in enumerate(words):\n",
    "            res_words.append(word)\n",
    "    return res_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resulted_function(img_path, path_to_save):\n",
    "    img = cv2.imread(img_path)\n",
    "    h_img, w_img, _ = img.shape\n",
    "    res_index = compare_thresh_indexes(img)\n",
    "    print('res_index ' + str(res_index))\n",
    "    words = latest_words_extraction(p, res_index)\n",
    "    for i, word in enumerate(words):\n",
    "        h, w, _ = word.shape\n",
    "        thresh1 = get_thresh_image(word, res_index)\n",
    "        percent = percent_of_white_pixels_word(thresh1)\n",
    "        if 0.7 <= percent <= 0.99 :\n",
    "            show(thresh1)\n",
    "            try:\n",
    "                if h >=  w/5 or w <= w_img / 15:\n",
    "                    little_words = prepare_thresh(thresh1)\n",
    "                    for k, little_word in enumerate(little_words):\n",
    "                        try:\n",
    "                            h_lw, w_lw = little_word.shape\n",
    "                            if h_lw >= h/5 and w_lw >= w/5:\n",
    "                                path = path_to_save + '/' + author + '_' + 'word_' + str(i) + str(k) + '.png'\n",
    "                                cv2.imwrite(path_to_save,little_word) \n",
    "                        except:\n",
    "                            path = path_to_save + '/' + author + '_' + 'word_' + str(i)+ '.png'\n",
    "                            cv2.imwrite(path_to_save,thresh1) \n",
    "            except (ZeroDivisionError, statistics.StatisticsError):\n",
    "                path = path_to_save + '/' + author + '_' + 'word_'+ str(i) + '.png'\n",
    "                cv2.imwrite(path_to_save,thresh1)             \n",
    "\n",
    "            path = path_to_save + '/' + author + '_' + 'word_' + str(i)+ '.png'\n",
    "            cv2.imwrite(path_to_save,thresh1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
