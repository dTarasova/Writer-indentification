{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words selection from handwriting documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import plot\n",
    "import statistics   \n",
    "from statistics import mean\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN = (0, 255, 0)\n",
    "BLUR = (255, 0, 0)\n",
    "RED = (0, 0, 255)\n",
    "\n",
    "def show(img):\n",
    "    \"\"\"show rgb image\"\"\"\n",
    "    ax = plt.axes([0,0,4,4], frameon=False)\n",
    "    ax.set_axis_off()\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "def show_gray(img):\n",
    "    \"\"\"show grayscale image\"\"\"\n",
    "    ax = plt.axes([0,0,4,4], frameon=False)\n",
    "    ax.set_axis_off()\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_words(path, words):\n",
    "    for i, word in enumerate(words):\n",
    "        cv2.imwrite(os.path.join(path , 'word_' + str(i) + '.png'), word)\n",
    "        \n",
    "def sort_w(word):\n",
    "    shape = word.shape\n",
    "    return shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to delete internal contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RECT:\n",
    "    \"\"\"Class that helps to  find where one contours are inside others\"\"\"\n",
    "    def __init__(self, x, y, h,  w):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "def is_rectangle_internal(R1,  R2):\n",
    "    \"\"\"If one rectangle contains another\"\"\"\n",
    "    if ((R2.x+R2.w) < (R1.x+R1.w)) and ((R2.x) > (R1.x)) and ((R2.y) > (R1.y)) and ((R2.y+R2.h) < (R1.y+R1.h)):\n",
    "            return True;\n",
    "    else:\n",
    "        return False;\n",
    "\n",
    "def get_rectangles_from_contours(contours, h_img, w_img):\n",
    "    \"\"\"Get all rectangles from contours, delete internal contours\"\"\"\n",
    "    rectangles = []\n",
    "    for i, ctr in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        if w >= w_img/50 and h >= h_img/50 and w <= w_img/2 and h <= h_img/10:\n",
    "            r = RECT(x,y,h, w)\n",
    "            rectangles += [r]\n",
    "    #Get only internal rectangles\n",
    "    resulted_rectangles = []\n",
    "    for i in range (len(rectangles)):\n",
    "        isSmall = True\n",
    "        r1 = rectangles[i]\n",
    "        for j in range(i+1, len(rectangles)):\n",
    "            r2 = rectangles[j]\n",
    "            if (is_rectangle_internal(r1, r2)):\n",
    "                isSmall = False       \n",
    "        if isSmall:\n",
    "            resulted_rectangles += [r1]\n",
    "    return resulted_rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions that helps to improve binarization index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_of_white_pixels_word(thresh_image):\n",
    "    \"\"\"Count percent of white pixels in the concrete word\"\"\"\n",
    "    white_pixels = 0\n",
    "    h, w, = thresh_image.shape\n",
    "    for i in range (h):\n",
    "        for j in range (w):\n",
    "            if (thresh_image[i][j] == 255):\n",
    "                white_pixels += 1\n",
    "\n",
    "    all_pixels = h *  w\n",
    "    return (round(white_pixels/all_pixels, 2))\n",
    "\n",
    "def percent_of_white_pixels(img, thresh_index):\n",
    "    \"\"\"Count percent of white pixels in the whole image\"\"\"\n",
    "    print(\"thresh_index\" + str(thresh_index))\n",
    "    h, w, _ = img.shape\n",
    "    # delete boundaries\n",
    "    image = img[40:h-40, 40:w-40]\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,thresh_index,255,cv2.THRESH_BINARY_INV)\n",
    "    show(thresh)\n",
    "    white_pixels = 0\n",
    "    h, w = thresh.shape\n",
    "    for i in range (h):\n",
    "        for j in range (w):\n",
    "            if (thresh[i][j] == 255):\n",
    "                white_pixels += 1\n",
    "\n",
    "    all_pixels = h *  w\n",
    "    return (round(white_pixels/all_pixels, 2))\n",
    "\n",
    "        \n",
    "def compare_thresh_indexes(img):\n",
    "    \"\"\"Determines which binarization index is the best is the best \"\"\"\n",
    "    #values to check which index is optimal for binarization\n",
    "    thresh_indexes = [107, 127, 147, 167, 187, 207, 227 ]\n",
    "    dict_with_norm_white_percent = {}\n",
    "    dict_with_big_white_percent = {}\n",
    "    best_percent = 100; best_index = 0; best_val = 100\n",
    "    \n",
    "    # Add to dictionary all values of each index binarization\n",
    "    for index in thresh_indexes:\n",
    "        percent = percent_of_white_pixels(img, index)\n",
    "        if percent >= 0.01 and percent <= 0.15:\n",
    "            dict_with_norm_white_percent[index] = percent\n",
    "            print(\"index \" + str(index) + \" - \" + str(percent))\n",
    "        else:\n",
    "            dict_with_big_white_percent[index] = percent\n",
    "            \n",
    "    # Select best index of binarization\n",
    "    if len(dict_with_norm_white_percent) == 0:\n",
    "        for index in dict_with_big_white_percent.keys():\n",
    "            if dict_with_big_white_percent[index] <= best_percent:\n",
    "                best_percent = dict_with_big_white_percent[index]\n",
    "                best_index = index\n",
    "            \n",
    "    else:\n",
    "        for index in dict_with_norm_white_percent.keys():\n",
    "            new_value = math.fabs(dict_with_norm_white_percent[index] - 0.07)\n",
    "            if new_value <= best_val:\n",
    "                best_val = new_value\n",
    "                best_percent = dict_with_norm_white_percent[index]\n",
    "                best_index = index\n",
    "    print(\"best index = \" + str(index) + \" - best_percent = \" + str(best_percent))\n",
    "    return index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions that helps to select words from too big contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresh_image(img, index):\n",
    "    if len(img.shape) == 3:\n",
    "        h, w, _  = img.shape\n",
    "    else:\n",
    "        h, w  = img.shape\n",
    "    contour = [0, 0, w, h]\n",
    "    binary = cv2.cvtColor(img.copy(), cv2.COLOR_RGB2GRAY)\n",
    "    show_gray(binary)\n",
    "    ret,thresh = cv2.threshold(binary,index,255,cv2.THRESH_BINARY)\n",
    "    show(thresh)\n",
    "    return thresh\n",
    "\n",
    "def prepare_binary_contour(contour):\n",
    "    \"\"\"Aggregate function to select lines\"\"\"\n",
    "    hists, average_black_height, average_white_height, lines_count = build_hists(contour)\n",
    "\n",
    "    sm_hists = smooth_hists(hists)\n",
    "    #show_hists(sm_hists)\n",
    "    valleys = find_valleys(sm_hists)\n",
    "    #show_valleys(contour, valleys)\n",
    "    lines, avg_height = get_lines(contour, valleys) \n",
    "\n",
    "    #show_lines(contour, lines)\n",
    "    if lines != []:\n",
    "        lines = filter_chunks(lines, average_black_height, average_white_height)\n",
    "    else: \n",
    "        return []\n",
    "\n",
    "    #show_lines(contour, lines)\n",
    "    created_lines = get_first_approach_lines(lines, average_black_height)\n",
    "    #draw_lines(contour, created_lines)\n",
    "\n",
    "    created_lines = sorted(created_lines, key = lambda x: x.data[0].y)\n",
    "    #draw_lines(contour, created_lines)\n",
    "    extracted_lines = cut_lines(contour, created_lines)\n",
    "    return extracted_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First approximation of lines - building histograms of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hists(image):\n",
    "    \"\"\"Build hist to each chunk\"\"\"\n",
    "    hists = []\n",
    "    chunks = get_chunks(image)\n",
    "    black_height = []; white_height = []\n",
    "    lines_count = []\n",
    "    for i, val in enumerate(chunks[:-1]):\n",
    "        chunk = image[:, val : chunks[i + 1]]\n",
    "        hist = np.sum(1 - (chunk / 255), axis=1)\n",
    "        current_black_height = 0\n",
    "        current_white_height = 0\n",
    "        count = 0\n",
    "        if hist[0] == 0:\n",
    "            current_black_height += 1\n",
    "        else:\n",
    "            current_white_height += 1\n",
    "        for pix in hist[1:]:\n",
    "            if pix == 0:\n",
    "                if current_black_height > 0:\n",
    "                    current_black_height += 1\n",
    "                else:\n",
    "                    current_black_height += 1\n",
    "                    white_height.append(current_white_height)\n",
    "                    current_white_height = 0\n",
    "            else:\n",
    "                if current_white_height > 0:\n",
    "                    current_white_height += 1\n",
    "                else:\n",
    "                    current_white_height += 1\n",
    "                    black_height.append(current_black_height)\n",
    "                    count += 1\n",
    "                    current_black_height = 0\n",
    "        lines_count.append(count)\n",
    "        hists.append(hist)\n",
    "    return hists, mean(black_height), mean(white_height), lines_count\n",
    "\n",
    "def smooth_hists(hists):\n",
    "    \"\"\"Smooth hists witch is got in function build_hists\"\"\"\n",
    "    new_hists = []\n",
    "    for hist in hists:\n",
    "        new_hists.append(median_smooth(hist))\n",
    "    return new_hists\n",
    "\n",
    "def median_smooth(signal, kernel_size = 5):\n",
    "    \"\"\"Smooth signal\"\"\"\n",
    "    smooth_signal = []\n",
    "    for i, val in enumerate(signal[:-kernel_size]):\n",
    "        smooth_signal.append(sum(signal[i: i + kernel_size]) / kernel_size)\n",
    "    return np.array(smooth_signal)\n",
    "\n",
    "def show_hists(hists):\n",
    "    \"\"\"\n",
    "    Draw hists\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    y = np.arange(len(hists[0]))\n",
    "    for i in range(len(hists)):\n",
    "        h = hists[i]\n",
    "        plt.plot(h[::-1] + i*35, y)\n",
    "    ax = plt.axes([0,0,1,1], frameon=False)\n",
    "    ax.set_axis_off()\n",
    "    plt.show()\n",
    "    fig.savefig('temp.png', dpi=fig.dpi)\n",
    "    \n",
    "def find_valleys(sm_hists, thresh = 1):\n",
    "    \"\"\"Finding troughs on smoothed histograms\"\"\"\n",
    "    valleys = []\n",
    "    interval_average_height = []\n",
    "    for curr in sm_hists:\n",
    "        curr[curr < thresh] = 0\n",
    "        valleys_ind, curr_valley = [], []\n",
    "        prev = 1\n",
    "        for i, val in enumerate(curr[:-1]):\n",
    "            if (val == 0 and prev != 0):\n",
    "                curr_valley.append(i)\n",
    "            if (val == 0 and curr[i + 1] != 0):\n",
    "                curr_valley.append(i)\n",
    "            if len(curr_valley) == 2:\n",
    "                valleys_ind.append(curr_valley)\n",
    "                interval_average_height.append(curr_valley[1] - curr_valley[0])\n",
    "                curr_valley = []\n",
    "            if len(curr_valley) == 1 and (i == len(curr) - 2):\n",
    "                curr_valley.append(i)\n",
    "                valleys_ind.append(curr_valley)\n",
    "            prev = val\n",
    "        valleys.append(valleys_ind)\n",
    "    return valleys\n",
    "\n",
    "def show_valleys(image, valleys, channels = 2):\n",
    "    chunks = get_chunks(image, channels)\n",
    "    img = image.copy()\n",
    "    \n",
    "    for i, y in enumerate(chunks[:-1]):\n",
    "        for (x_1, x_2) in valleys[i]:\n",
    "            cv2.line(img, (y, x_1), (chunks[i + 1], x_1),GREEN,3)\n",
    "            cv2.line(img, (y, x_2), (chunks[i + 1], x_2),RED,3)\n",
    "    if channels == 3:\n",
    "        show(img)\n",
    "    else:\n",
    "        show_gray(img)     \n",
    "        \n",
    "def get_lines(image, valleys, channels = 2):\n",
    "    \"\"\"Calculate the middle line in the trough and the average line height\"\"\"\n",
    "    total_lines = []\n",
    "    chunks = get_chunks(image, channels)\n",
    "    for i, chunk in enumerate(chunks[:-1]):\n",
    "        chunk_lines = []\n",
    "        for val in valleys[i]:\n",
    "            chunk_lines.append(Trait(chunk, chunks[i+1], sum(val) // len(val)))\n",
    "        total_lines.append(chunk_lines)\n",
    "    \n",
    "    height = []\n",
    "    for i, line in enumerate(total_lines):\n",
    "        for j, trait in enumerate(line[:-1]):\n",
    "            height.append(abs(trait.y_1 - line[j + 1].y_1))\n",
    "    height = sum(height) / len(height)\n",
    "    return total_lines, height\n",
    "\n",
    "def show_lines(image, lines):\n",
    "    img = image.copy()\n",
    "    for chunk in lines:\n",
    "        for line in chunk:\n",
    "            cv2.line(img, (line.x_1, line.y_1), (line.x_2, line.y_1),GREEN,3)\n",
    "    show(img)\n",
    "    \n",
    "def get_chunks(image, channels = 1):\n",
    "    \"\"\"\n",
    "    Split image on chunks, each chunk is 10 percent of image width\n",
    "    return: array with y-coordinates\n",
    "    \"\"\"\n",
    "    n, m = image.shape\n",
    "    return np.arange(0, m + 1, m // 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes that helps to improve lines selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Point = namedtuple('Point', ['x' , 'y'])\n",
    "\n",
    "class Line:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.last_trait = None\n",
    "        \n",
    "    def continue_line(self, trait):\n",
    "        self.data.append(Point(trait.x_1, trait.y_1))\n",
    "        self.data.append(Point(trait.x_2, trait.y_1))\n",
    "\n",
    "class Trait:\n",
    "    def __init__(self, x_1, x_2, y_1):\n",
    "        self.x_1 = x_1\n",
    "        self.x_2 = x_2\n",
    "        self.y_1 = y_1\n",
    "        #self.y_2 = y_2\n",
    "    \n",
    "    def dist(self, other):\n",
    "        return ((self.x_2 - other.x_1) ** 2 + (self.y_1 - other.y_1) ** 2) ** (1 / 2)\n",
    "    \n",
    "    def print_(self):\n",
    "        print('x_1: {}  x_2: {}  y: {}'.format(self.x_1, self.x_2, self.y_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical functions to improve lines selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_chunk(chunk, avg_black_height, average_white_height):\n",
    "    if chunk == []:\n",
    "        return []\n",
    "    prev = chunk[0]\n",
    "    new_traits = [prev]\n",
    "    for i, trait in enumerate(chunk[1:-1]):\n",
    "        next_trait = chunk[i + 2]\n",
    "        if abs(prev.y_1 - trait.y_1) > (avg_black_height + average_white_height/4) \\\n",
    "            and abs(next_trait.y_1 - trait.y_1) > (avg_black_height+ average_white_height/4):\n",
    "            new_traits.append(trait)\n",
    "            prev = trait\n",
    "    new_traits.append(chunk[-1])\n",
    "    return new_traits\n",
    "\n",
    "def filter_chunks(chunks, avg_black_height, average_white_height):\n",
    "    new_chunks = []\n",
    "    if chunks == []:\n",
    "        return []\n",
    "    for chunk in chunks:\n",
    "        new_chunks.append(filter_chunk(chunk, avg_black_height, average_white_height))\n",
    "    return new_chunks\n",
    "\n",
    "def get_first_approach_lines(chunk_with_traits, avg_height):\n",
    "    \"\"\"\n",
    "    Get first approach of splitting lines\n",
    "    \"\"\"\n",
    "    if chunk_with_traits is None:\n",
    "        return []\n",
    "    created_lines = connect_two_chunks(chunk_with_traits[0], chunk_with_traits[1], avg_height)\n",
    "    connect_start_lines_with_next_chunks(created_lines, chunk_with_traits[2], avg_height)\n",
    "    for chunk in chunk_with_traits[3:]:\n",
    "        connect_lines_with_chunk(created_lines, chunk, avg_height)\n",
    "    #print('avg height = ' + str(avg_height))\n",
    "    return created_lines\n",
    "                \n",
    "def connect_two_chunks(chunk_1, chunk_2, avg_height):\n",
    "    if chunk_1 == [] or chunk_2 == []:\n",
    "        return []\n",
    "    all_inds_from_chunk2 = [i for i in range(len(chunk_2))]\n",
    "    used_traits_from_chunk2 = []\n",
    "    created_lines = []\n",
    "    for trait_1 in chunk_1:\n",
    "        minimum = sys.maxsize\n",
    "        min_trait = Trait(trait_1.x_1, trait_1.x_2, 100)\n",
    "        for j, trait_2 in enumerate(chunk_2):\n",
    "            if trait_1.dist(trait_2) <  minimum:\n",
    "                minimum = trait_1.dist(trait_2)\n",
    "                min_trait = trait_2\n",
    "            if minimum >= 2 * avg_height / 3:\n",
    "                min_trait = Trait(min_trait.x_1, min_trait.x_2, trait_1.y_1)\n",
    "                \n",
    "            if (min_trait.x_1 == trait_2.x_1) and (min_trait.x_2 == trait_2.x_2) \\\n",
    "                and (min_trait.y_1 == trait_2.y_1):\n",
    "                used_traits_from_chunk2.append(j)\n",
    "        new_line = Line()\n",
    "        new_line.continue_line(trait_1)\n",
    "        new_line.continue_line(min_trait)\n",
    "        new_line.last_trait = min_trait\n",
    "        created_lines.append(new_line)\n",
    "    unused_traits = list(set(all_inds_from_chunk2) - set(used_traits_from_chunk2))\n",
    "\n",
    "    for trait in unused_traits:\n",
    "        chunk = chunk_2[trait]\n",
    "        new_line = Line()\n",
    "        start_trait = Trait(chunk_1[0].x_1, chunk.x_1, chunk.y_1)\n",
    "        new_line.continue_line(start_trait)\n",
    "        new_line.continue_line(chunk)\n",
    "        new_line.last_trait = chunk\n",
    "        created_lines.append(new_line)\n",
    "    return created_lines\n",
    "\n",
    "def connect_start_lines_with_next_chunks(lines, chunk, avg_height):\n",
    "    all_inds_from_chunk = [i for i in range(len(chunk))]\n",
    "    used_traits_from_chunk = []\n",
    "    for line in lines:\n",
    "        trait_1 = line.last_trait\n",
    "        min_trait = Trait(trait_1.x_1, trait_1.x_2, 100)\n",
    "        minimum = sys.maxsize\n",
    "        for j, trait_2 in enumerate(chunk):\n",
    "            if trait_1.dist(trait_2) <  minimum:\n",
    "                minimum = trait_1.dist(trait_2)\n",
    "                min_trait = trait_2\n",
    "            if minimum >= avg_height / 2.0:\n",
    "                min_trait = Trait(min_trait.x_1, min_trait.x_2, trait_1.y_1)\n",
    "            if (min_trait.x_1 == trait_2.x_1) and (min_trait.x_2 == trait_2.x_2) \\\n",
    "                and (min_trait.y_1 == trait_2.y_1):\n",
    "                used_traits_from_chunk.append(j)\n",
    "        line.continue_line(min_trait)\n",
    "        line.last_trait = min_trait\n",
    "    unused_traits = list(set(all_inds_from_chunk) - set(used_traits_from_chunk))\n",
    "    print(unused_traits)\n",
    "    for i in unused_traits:\n",
    "        trait = chunk[i]\n",
    "        start_trait = Trait(0, trait.x_1, trait.y_1)\n",
    "        new_line = Line()\n",
    "        new_line.continue_line(start_trait)\n",
    "        new_line.continue_line(trait)\n",
    "        new_line.last_trait = trait\n",
    "        lines.append(new_line)\n",
    "        \n",
    "def connect_lines_with_chunk(lines, chunk, avg_height):\n",
    "    \"\"\" Combine the remaining chunk and already created lines\"\"\"\n",
    "    for line in lines: \n",
    "        trait_1 = line.last_trait\n",
    "        minimum = sys.maxsize\n",
    "        if len(chunk) == 0:\n",
    "            return\n",
    "        for trait_2 in chunk:\n",
    "            if trait_1.dist(trait_2) <  minimum:\n",
    "                minimum = trait_1.dist(trait_2)\n",
    "                min_trait = trait_2\n",
    "            if minimum >=  avg_height / 1:\n",
    "            \n",
    "                min_trait = Trait(min_trait.x_1, min_trait.x_2, trait_1.y_1)\n",
    "        line.continue_line(min_trait)\n",
    "        line.last_trait = min_trait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cut and draw lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_line(image, line_1, line_2):\n",
    "    n, m = image.shape\n",
    "    img = image.copy()\n",
    "    x_list = []\n",
    "    for i, point in enumerate(line_1.data[:-1]):\n",
    "        next_point = line_1.data[i + 1]\n",
    "        img[:point.y, point.x:next_point.x] = 255\n",
    "        x_list.append(point.x)\n",
    "    for i, point in enumerate(line_2.data[:-1]):\n",
    "        next_point = line_2.data[i + 1]\n",
    "        img[point.y:n, point.x:next_point.x] = 255\n",
    "        x_list.append(point.x)\n",
    "    max_x = max(x_list)\n",
    "    img[:, max_x:m] = 255\n",
    "    inds = np.argwhere(img == 0)\n",
    "    if len(inds) != 0:\n",
    "        x_min = min(inds[:, 0])\n",
    "        x_max = max(inds[:, 0])\n",
    "        y_min = min(inds[:, 1])\n",
    "        y_max = max(inds[:, 1])\n",
    "        show_gray(img[x_min:x_max,:])\n",
    "        return img[x_min:x_max, y_min:y_max]       \n",
    "\n",
    "def cut_lines(image, created_lines):\n",
    "    lines = []\n",
    "    for i, line in enumerate(created_lines[:-1]):\n",
    "        lines.append(cut_line(image, line, created_lines[i + 1]))\n",
    "    return lines\n",
    "\n",
    "def draw_line(image, line):\n",
    "    img = image.copy()\n",
    "    color = [random.randint(0, 255) for _ in range(3)]\n",
    "    for i, point in enumerate(line.data[:-1]):\n",
    "        next_point = line.data[i + 1]\n",
    "        cv2.line(img, (point.x, point.y), (next_point.x, next_point.y), color ,3)\n",
    "    return img\n",
    "    \n",
    "def draw_lines(image, lines, channels = 2):\n",
    "    \"\"\"Draw splitting lines\"\"\"\n",
    "    img = image.copy()\n",
    "    for line in lines:\n",
    "        img = draw_line(img, line)\n",
    "    if channels == 3:\n",
    "        cv2.imwrite(\"12345.png\", img)\n",
    "        show(img)\n",
    "    else:\n",
    "        show_gray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words extraction from line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_line(line, min_width = 10, thresh =  100): #400000\n",
    "    \"\"\"\n",
    "    line : grayscale line\n",
    "    min_width : min space length\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    if line is None:\n",
    "        return words\n",
    "    n, m = line.shape\n",
    "    image = cv2.bitwise_not(line)\n",
    "    y = np.sum(image // 255, axis = 0)\n",
    "\n",
    "    _, inds = np.where([y == 0])\n",
    "\n",
    "    start = 0\n",
    "    spaces = []\n",
    "    for i, ind in enumerate(inds[:-1]):\n",
    "        if (ind + 1 == inds[i + 1]) and (start == 0):\n",
    "            start = ind\n",
    "        elif (ind + 1 < inds[i + 1]) and (start != 0):\n",
    "            if (ind - start) >= min_width:\n",
    "                spaces.append([int(start), int(ind)])\n",
    "                start = 0\n",
    "            else:\n",
    "                start = 0\n",
    "\n",
    "    spaces = np.ravel(spaces)\n",
    "    spaces = np.insert(spaces, [0, len(spaces)], [0, m])\n",
    "    spaces = spaces.reshape(len(spaces) // 2, 2)     \n",
    "    \n",
    "    for inds in spaces:\n",
    "        word = line[:, int(inds[0]): int(inds[1])]\n",
    "        print(\"sum\", np.sum(word))\n",
    "        #show_gray(word)\n",
    "        if np.sum(1 - (word / 255)) > thresh:\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "def extract_words(lines):\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        words += get_words_from_line(line)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resulted function to prepare an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contours_extraction(img_path, thresh_index):\n",
    "    img = cv2.imread(img_path)\n",
    "    h_img, w_img, _ = img.shape\n",
    "    image = img[40:h_img-40, 40:w_img-40]\n",
    "    #show(image)\n",
    "    words = []\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,thresh_index,255,cv2.THRESH_BINARY_INV)\n",
    "    #show(thresh)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE )\n",
    "    #sort contours\n",
    "    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    resulted_rectangles = get_rectangles_from_contours(sorted_ctrs, h_img, w_img)\n",
    "    \n",
    "    # Show how resulted contours will be selected at image\n",
    "    for rect in resulted_rectangles:\n",
    "        cv2.rectangle(thresh,(rect.x,rect.y),( rect.x + rect.w, rect.y + rect.h ),(255,255,255),2)\n",
    "    show(thresh)\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    image_to_cut = img[40:h_img-40, 40:w_img-40]\n",
    "    \n",
    "    #Add words into array\n",
    "    for rect in resulted_rectangles:\n",
    "        roi = image_to_cut.copy()[rect.y:rect.y+rect.h, rect.x:rect.x+rect.w]\n",
    "        words.append(roi)\n",
    "        \n",
    "    return words\n",
    "    \n",
    "    #words.sort(key = sort_w, reverse = True)\n",
    "    #res_words = []\n",
    "    #for i, word in enumerate(words):\n",
    "    #       res_words.append(word)\n",
    "    #return res_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resulted_function(img_path, path_to_save):\n",
    "    img = cv2.imread(img_path)\n",
    "    index1 = img_path.index('/')+1\n",
    "    index2 = img_path.index('.')\n",
    "    author = img_path[index1:index2]\n",
    "    h_img, w_img, _ = img.shape\n",
    "    # Get optimal binarization index\n",
    "    res_index = compare_thresh_indexes(img)\n",
    "    print('res_index ' + str(res_index))\n",
    "    \n",
    "    contours = contours_extraction(img_path, res_index)\n",
    "    for i, contour in enumerate(contours):\n",
    "        h, w, _ = contour.shape\n",
    "        binary_contour = get_thresh_image(contour, res_index)\n",
    "        percent = percent_of_white_pixels_word(binary_contour)\n",
    "        \n",
    "        if 0.7 <= percent <= 0.95 :\n",
    "            print('contour № ' + str(i))\n",
    "            show(binary_contour)\n",
    "            try:\n",
    "                if h >=  w/5 or w <= w_img / 15:\n",
    "                    words = prepare_binary_contour(binary_contour)\n",
    "                    #if lines is not None:\n",
    "                        #words = extract_words(lines)\n",
    "                    for k, word in enumerate(words):\n",
    "                        try:\n",
    "                            h_lw, w_lw = word.shape\n",
    "                            if h_lw >= h/5 and w_lw >= w/5:\n",
    "                                path = path_to_save + '/' + author + '_' + 'word_' + str(i) + str(k) + '.png'\n",
    "                                cv2.imwrite(path, word) \n",
    "                        except:\n",
    "                            path = path_to_save + '/' + author + '_' + 'word_' + str(i)+ '.png'\n",
    "                            cv2.imwrite(path,binary_contour) \n",
    "                else:\n",
    "                    path = path_to_save + '/' + author + '_' + 'word_'+ str(i) + '.png'\n",
    "                    cv2.imwrite(path,binary_contour)   \n",
    "            except (ZeroDivisionError, statistics.StatisticsError):\n",
    "                path = path_to_save + '/' + author + '_' + 'word_'+ str(i) + '.png'\n",
    "                cv2.imwrite(path,binary_contour)             \n",
    "\n",
    "            #path = path_to_save + '/' + author + '_' + 'word_' + str(i)+ '.png'\n",
    "           # cv2.imwrite(path,binary_contour) \n",
    "    print(len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_for_image = ''\n",
    "path_for_save = ''\n",
    "resulted_function(path, path_for_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
